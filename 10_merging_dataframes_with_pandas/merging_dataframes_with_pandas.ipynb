{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Merging DataFrames with pandas</center>\n",
    "\n",
    "[Data Camp Link](https://www.datacamp.com/courses/merging-dataframes-with-pandas)\n",
    "\n",
    "[Chapter 1: Preparing data](#Chapter-1:-Preparing-data) <br>\n",
    "[Chapter 2: Concatenating data](#Chapter-2:-Concatenating-data) <br>\n",
    "[Chapter 3: Merging data](#Chapter-3:-Merging-data) <br>\n",
    "[Chapter 4: Case Study - Summer Olympics](#Chapter-4:-Case-Study---Summer-Olympics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Preparing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all main imports here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading DataFrames from multiple files\n",
    "\n",
    "When data is spread among several files, you usually invoke pandas' `read_csv()` (or a similar data import function) multiple times to load the data into several DataFrames.\n",
    "\n",
    "The data files for this example have been derived from a [list of Olympic medals awarded between 1896 & 2008](https://www.theguardian.com/sport/datablog/2012/jun/25/olympic-medal-winner-list-data) compiled by the Guardian.\n",
    "\n",
    "The column labels of each DataFrame are `NOC`, `Country`, & `Total` where `NOC` is a three-letter code for the name of the country and `Total` is the number of medals of that type won (bronze, silver, or gold).\n",
    "\n",
    "*This course touches on a lot of concepts you may have forgotten, so if you ever need a quick refresher, download the [Pandas Cheat Sheet](https://datacamp-community-prod.s3.amazonaws.com/9f0f2ae1-8bd8-4302-a67b-e17f3059d9e8) and keep it handy!*\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Import `pandas` as `pd`.\n",
    "- Read the file `'Bronze.csv'` into a DataFrame called `bronze`.\n",
    "- Read the file `'Silver.csv'` into a DataFrame called `silver`.\n",
    "- Read the file `'Gold.csv'` into a DataFrame called `gold`.\n",
    "- Print the first 5 rows of the DataFrame `gold`. This has been done for you, so hit 'Submit Answer' to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country   Total\n",
      "0  USA   United States  2088.0\n",
      "1  URS    Soviet Union   838.0\n",
      "2  GBR  United Kingdom   498.0\n",
      "3  FRA          France   378.0\n",
      "4  GER         Germany   407.0\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# Read 'Bronze.csv' into a DataFrame: bronze\n",
    "bronze = pd.read_csv(\"data/Bronze.csv\")\n",
    "\n",
    "# Read 'Silver.csv' into a DataFrame: silver\n",
    "silver = pd.read_csv(\"data/Silver.csv\")\n",
    "\n",
    "# Read 'Gold.csv' into a DataFrame: gold\n",
    "gold = pd.read_csv(\"data/Gold.csv\")\n",
    "\n",
    "# Print the first five rows of gold\n",
    "print(gold.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading DataFrames from multiple files in a loop\n",
    "\n",
    "As you saw in the video, loading data from multiple files into DataFrames is more efficient in a *loop* or a *list comprehension*.\n",
    "\n",
    "Notice that this approach is not restricted to working with CSV files. That is, even if your data comes in other formats, as long as pandas has a suitable data import function, you can apply a loop or comprehension to generate a list of DataFrames imported from the source files.\n",
    "\n",
    "Here, you'll continue working with [The Guardian's Olympic medal dataset](https://www.theguardian.com/sport/datablog/2012/jun/25/olympic-medal-winner-list-data).\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Create a list of file names called `filenames` with three strings `'Gold.csv'`, `'Silver.csv'`, & `'Bronze.csv'`. This has been done for you.\n",
    "- Use a `for` loop to create another list called `dataframes` containing the three DataFrames loaded from `filenames`:\n",
    "    - Iterate over `filenames`.\n",
    "    - Read each CSV file in `filenames` into a DataFrame and append it to `dataframes` by using `pd.read_csv()` inside a call to `.append()`.\n",
    "- Print the first 5 rows of the first DataFrame of the list `dataframes`. This has been done for you, so hit 'Submit Answer' to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country   Total\n",
      "0  USA   United States  2088.0\n",
      "1  URS    Soviet Union   838.0\n",
      "2  GBR  United Kingdom   498.0\n",
      "3  FRA          France   378.0\n",
      "4  GER         Germany   407.0\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# Create the list of file names: filenames\n",
    "filenames = ['data/Gold.csv', 'data/Silver.csv', 'data/Bronze.csv']\n",
    "\n",
    "# Create the list of three DataFrames: dataframes\n",
    "dataframes = []\n",
    "for filename in filenames:\n",
    "    dataframes.append(pd.read_csv(filename))\n",
    "\n",
    "# Print top 5 rows of 1st DataFrame in dataframes\n",
    "print(dataframes[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining DataFrames from multiple data files\n",
    "\n",
    "In this exercise, you'll *combine* the three DataFrames from earlier exercises - `gold`, `silver`, & `bronze` - into a single DataFrame called `medals`. The approach you'll use here is clumsy. Later on in the course, you'll see various powerful methods that are frequently used in practice for *concatenating* or *merging* DataFrames.\n",
    "\n",
    "Remember, the column labels of each DataFrame are `NOC`, `Country`, and `Total`, where `NOC` is a three-letter code for the name of the country and `Total` is the number of medals of that type won.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Construct a copy of the DataFrame `gold` called `medals` using the `.copy()` method.\n",
    "- Create a list called `new_labels` with entries `'NOC'`, `'Country'`, & `'Gold'`. This is the same as the column labels from `gold` with the column label `'Total'` replaced by `'Gold'`.\n",
    "- Rename the columns of `medals` by assigning `new_labels` to `medals.columns`.\n",
    "- Create new columns `'Silver'` and `'Bronze'` in `medals` using `silver['Total']` & `bronze['Total']`.\n",
    "- Print the top 5 rows of the final DataFrame `medals`. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country    Gold  Silver  Bronze\n",
      "0  USA   United States  2088.0  1195.0  1052.0\n",
      "1  URS    Soviet Union   838.0   627.0   584.0\n",
      "2  GBR  United Kingdom   498.0   591.0   505.0\n",
      "3  FRA          France   378.0   461.0   475.0\n",
      "4  GER         Germany   407.0   350.0   454.0\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# Make a copy of gold: medals\n",
    "medals = gold.copy()\n",
    "\n",
    "# Create list of new column labels: new_labels\n",
    "new_labels = ['NOC', 'Country', 'Gold']\n",
    "\n",
    "# Rename the columns of medals using new_labels\n",
    "medals.columns = new_labels\n",
    "\n",
    "# Add columns 'Silver' & 'Bronze' to medals\n",
    "medals['Silver'] = silver['Total']\n",
    "medals['Bronze'] = bronze['Total']\n",
    "\n",
    "# Print the head of medals\n",
    "print(medals.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting DataFrame with the Index & columns\n",
    "\n",
    "It is often useful to rearrange the sequence of the rows of a DataFrame by *sorting*. You don't have to implement these yourself; the principal methods for doing this are `.sort_index()` and `.sort_values()`.\n",
    "\n",
    "In this exercise, you'll use these methods with a DataFrame of temperature values indexed by month names. You'll sort the rows alphabetically using the Index and numerically using a column. Notice, for this data, the original ordering is probably most useful and intuitive: the purpose here is for you to understand what the sorting methods do.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Read `'monthly_max_temp.csv'` into a DataFrame called `weather1` with `'Month'` as the index.\n",
    "- Sort the index of `weather1` in alphabetical order using the `.sort_index()` method and store the result in `weather2`.\n",
    "- Sort the index of `weather1` in *reverse* alphabetical order by specifying the additional keyword argument `ascending=False` inside `.sort_index()`.\n",
    "- Use the `.sort_values()` method to sort `weather1` in increasing numerical order according to the *values* of the column `'Max TemperatureF'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Max TemperatureF\n",
      "Month                  \n",
      "Jan                  68\n",
      "Feb                  60\n",
      "Mar                  68\n",
      "Apr                  84\n",
      "May                  88\n",
      "       Max TemperatureF\n",
      "Month                  \n",
      "Apr                  84\n",
      "Aug                  86\n",
      "Dec                  68\n",
      "Feb                  60\n",
      "Jan                  68\n",
      "       Max TemperatureF\n",
      "Month                  \n",
      "Sep                  90\n",
      "Oct                  84\n",
      "Nov                  72\n",
      "May                  88\n",
      "Mar                  68\n",
      "       Max TemperatureF\n",
      "Month                  \n",
      "Feb                  60\n",
      "Jan                  68\n",
      "Mar                  68\n",
      "Dec                  68\n",
      "Nov                  72\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# Read 'monthly_max_temp.csv' into a DataFrame: weather1\n",
    "weather1 = pd.read_csv(\"data/monthly_max_temp.csv\", index_col = 'Month')\n",
    "\n",
    "# Print the head of weather1\n",
    "print(weather1.head())\n",
    "\n",
    "# Sort the index of weather1 in alphabetical order: weather2\n",
    "weather2 = weather1.sort_index()\n",
    "\n",
    "# Print the head of weather2\n",
    "print(weather2.head())\n",
    "\n",
    "# Sort the index of weather1 in reverse alphabetical order: weather3\n",
    "weather3 = weather1.sort_index(ascending=False)\n",
    "\n",
    "# Print the head of weather3\n",
    "print(weather3.head())\n",
    "\n",
    "# Sort weather1 numerically using the values of 'Max TemperatureF': weather4\n",
    "weather4 = weather1.sort_values('Max TemperatureF')\n",
    "\n",
    "# Print the head of weather4\n",
    "print(weather4.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindexing DataFrame from a list\n",
    "\n",
    "Sorting methods are not the only way to change DataFrame Indexes. There is also the `.reindex()` method.\n",
    "\n",
    "In this exercise, you'll reindex a DataFrame of quarterly-sampled mean temperature values to contain monthly samples (this is an example of *upsampling* or increasing the rate of samples, which you may recall from the [pandas Foundations](https://www.datacamp.com/courses/pandas-foundations) course).\n",
    "\n",
    "The original data has the first month's abbreviation of the quarter (three-month interval) on the Index, namely `Apr`, `Jan`, `Jul`, and `Oct`. This data has been loaded into a DataFrame called `weather1` and has been printed in its entirety in the IPython Shell. Notice it has only four rows (corresponding to the first month of each quarter) and that the rows are not sorted chronologically.\n",
    "\n",
    "You'll initially use a list of all twelve month abbreviations and subsequently apply the `.ffill()` method to *forward-fill* the null entries when upsampling. This list of month abbreviations has been pre-loaded as `year`.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Reorder the rows of `weather1` using the `.reindex()` method with the list `year` as the argument, which contains the abbreviations for each month.\n",
    "- Reorder the rows of `weather1` just as you did above, this time chaining the `.ffill()` method to replace the null values with the last preceding non-null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max TemperatureF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Apr</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jan</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jul</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oct</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Max TemperatureF\n",
       "Month                  \n",
       "Apr                  84\n",
       "Jan                  68\n",
       "Jul                  91\n",
       "Oct                  84"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather1 = weather1.loc[['Apr', 'Jan', 'Jul', 'Oct'],:]\n",
    "weather1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Max TemperatureF\n",
      "Month                  \n",
      "Jan                68.0\n",
      "Feb                 NaN\n",
      "Mar                 NaN\n",
      "Apr                84.0\n",
      "May                 NaN\n",
      "Jun                 NaN\n",
      "Jul                91.0\n",
      "Aug                 NaN\n",
      "Sep                 NaN\n",
      "Oct                84.0\n",
      "Nov                 NaN\n",
      "Dec                 NaN\n",
      "\n",
      "\n",
      "       Max TemperatureF\n",
      "Month                  \n",
      "Jan                68.0\n",
      "Feb                68.0\n",
      "Mar                68.0\n",
      "Apr                84.0\n",
      "May                84.0\n",
      "Jun                84.0\n",
      "Jul                91.0\n",
      "Aug                91.0\n",
      "Sep                91.0\n",
      "Oct                84.0\n",
      "Nov                84.0\n",
      "Dec                84.0\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "year = ['Jan',\n",
    " 'Feb',\n",
    " 'Mar',\n",
    " 'Apr',\n",
    " 'May',\n",
    " 'Jun',\n",
    " 'Jul',\n",
    " 'Aug',\n",
    " 'Sep',\n",
    " 'Oct',\n",
    " 'Nov',\n",
    " 'Dec']\n",
    "\n",
    "# Reindex weather1 using the list year: weather2\n",
    "weather2 = weather1.reindex(year)\n",
    "\n",
    "# Print weather2\n",
    "print(weather2)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Reindex weather1 using the list year with forward-fill: weather3\n",
    "weather3 = weather1.reindex(year).ffill()\n",
    "\n",
    "# Print weather3\n",
    "print(weather3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that values corresponding to months missing from `weather1` are filled with `NaN` values in `weather2`. This does not happen in `weather3`, since you used forward-fill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindexing using another DataFrame Index\n",
    "\n",
    "Another common technique is to reindex a DataFrame using the Index of another DataFrame. The DataFrame `.reindex()` method can accept the Index of a DataFrame or Series as input. You can access the Index of a DataFrame with its `.index` attribute.\n",
    "\n",
    "The [Baby Names Dataset](https://www.data.gov/developers/baby-names-dataset/) from [data.gov](http://data.gov/) summarizes counts of names (with genders) from births registered in the US since 1881. In this exercise, you will start with two baby-names DataFrames `names_1981` and `names_1881` loaded for you.\n",
    "\n",
    "The DataFrames `names_1981` and `names_1881` both have a MultiIndex with levels `name` and `gender` giving unique labels to counts in each row. If you're interested in seeing how the MultiIndexes were set up, `names_1981` and `names_1881` were read in using the following commands:\n",
    "\n",
    "`names_1981 = pd.read_csv('names1981.csv', header=None, names=['name','gender','count'], index_col=(0,1))\n",
    "names_1881 = pd.read_csv('names1881.csv', header=None, names=['name','gender','count'], index_col=(0,1))`\n",
    "\n",
    "As you can see by looking at their shapes, which have been printed in the IPython Shell, the DataFrame corresponding to 1981 births is much larger, reflecting the greater diversity of names in 1981 as compared to 1881.\n",
    "\n",
    "Your job here is to use the DataFrame `.reindex()` and `.dropna()` methods to make a DataFrame `common_names` counting names from 1881 that were still popular in 1981.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Create a new DataFrame `common_names` by reindexing `names_1981` using the `index` attribute of the DataFrame `names_1881` of older names.\n",
    "- Print the shape of the new `common_names` DataFrame. This has been done for you. It should be the same as that of `names_1881`.\n",
    "- Drop the rows of `common_names` that have null counts using the `.dropna()` method. These rows correspond to names that fell out of fashion between 1881 & 1981.\n",
    "- Print the shape of the reassigned `common_names` DataFrame. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mary</th>\n",
       "      <th>F</th>\n",
       "      <td>6919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anna</th>\n",
       "      <th>F</th>\n",
       "      <td>2698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count\n",
       "name gender       \n",
       "Mary F        6919\n",
       "Anna F        2698"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the dataset. there are no header in the original files\n",
    "names_1981 = pd.read_csv('data/names1981.csv', header=None, names=['name','gender','count'], index_col=(0,1))\n",
    "names_1881 = pd.read_csv('data/names1881.csv', header=None, names=['name','gender','count'], index_col=(0,1))\n",
    "\n",
    "# see how it looks\n",
    "names_1881.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of names_1981:  (19455, 1)\n",
      "The shape of names_1881:  (1935, 1)\n"
     ]
    }
   ],
   "source": [
    "# print the shapes\n",
    "print(\"The shape of names_1981: \", names_1981.shape)\n",
    "print(\"The shape of names_1881: \", names_1881.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1935, 1)\n",
      "(1587, 1)\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# Reindex names_1981 with index of names_1881: common_names\n",
    "common_names = names_1981.reindex(names_1881.index)\n",
    "\n",
    "# Print shape of common_names\n",
    "print(common_names.shape)\n",
    "\n",
    "# Drop rows with null counts: common_names\n",
    "common_names = common_names.dropna()\n",
    "\n",
    "# Print shape of new common_names\n",
    "print(common_names.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like **348** names fell out of fashion between 1881 and 1981!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting in arithmetic formulas\n",
    "\n",
    "In this exercise, you'll work with weather data pulled from [wunderground.com](https://www.wunderground.com/). The DataFrame `weather` has been pre-loaded along with `pandas` as `pd`. It has 365 rows (observed each day of the year 2013 in Pittsburgh, PA) and 22 columns reflecting different weather measurements each day.\n",
    "\n",
    "You'll subset a collection of columns related to temperature measurements in degrees Fahrenheit, convert them to degrees Celsius, and relabel the columns of the new DataFrame to reflect the change of units.\n",
    "\n",
    "Remember, ordinary arithmetic operators (like `+`, `-`, `*`, and `/`) *broadcast* scalar values to conforming DataFrames when combining scalars & DataFrames in arithmetic expressions. Broadcasting also works with pandas Series and NumPy arrays.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Create a new DataFrame `temps_f` by extracting the columns `'Min TemperatureF'`, `'Mean TemperatureF'`, & `'Max TemperatureF'` from `weather` as a new DataFrame `temps_f`. To do this, pass the relevant columns as a list to `weather[]`.\n",
    "- Create a new DataFrame `temps_c` from `temps_f` using the formula `(temps_f - 32) * 5/9`.\n",
    "- Rename the columns of `temps_c` to replace `'F'` with `'C'` using the `.str.replace('F', 'C')` method on `temps_c.columns`.\n",
    "- Print the first 5 rows of DataFrame `temps_c`. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min TemperatureF</th>\n",
       "      <th>Mean TemperatureF</th>\n",
       "      <th>Max TemperatureF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Min TemperatureF  Mean TemperatureF  Max TemperatureF\n",
       "Date                                                             \n",
       "2013-01-01                21                 28                32\n",
       "2013-01-02                17                 21                25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the dataset\n",
    "weather = pd.read_csv('data/pittsburgh2013.csv', index_col = 'Date', parse_dates = True)\n",
    "weather[['Min TemperatureF', 'Mean TemperatureF', 'Max TemperatureF']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Min TemperatureC  Mean TemperatureC  Max TemperatureC\n",
      "Date                                                             \n",
      "2013-01-01         -6.111111          -2.222222          0.000000\n",
      "2013-01-02         -8.333333          -6.111111         -3.888889\n",
      "2013-01-03         -8.888889          -4.444444          0.000000\n",
      "2013-01-04         -2.777778          -2.222222         -1.111111\n",
      "2013-01-05         -3.888889          -1.111111          1.111111\n"
     ]
    }
   ],
   "source": [
    "# Extract selected columns from weather as new DataFrame: temps_f\n",
    "temps_f = weather[['Min TemperatureF', 'Mean TemperatureF', 'Max TemperatureF']]\n",
    "\n",
    "# Convert temps_f to celsius: temps_c\n",
    "temps_c = (temps_f - 32) * 5/9\n",
    "\n",
    "# Rename 'F' in column names with 'C': temps_c.columns\n",
    "temps_c.columns = temps_c.columns.str.replace('F', 'C')\n",
    "\n",
    "# Print first 5 rows of temps_c\n",
    "print(temps_c.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing percentage growth of GDP\n",
    "\n",
    "Your job in this exercise is to compute the yearly percent-change of US GDP ([Gross Domestic Product](https://en.wikipedia.org/wiki/Gross_domestic_product)) since 2008.\n",
    "\n",
    "The data has been obtained from the [Federal Reserve Bank of St. Louis](https://fred.stlouisfed.org/series/GDP/downloaddata) and is available in the file `GDP.csv`, which contains *quarterly* data; you will resample it to annual sampling and then compute the annual growth of GDP. For a refresher on resampling, check out the relevant material from [pandas Foundations](https://campus.datacamp.com/courses/pandas-foundations/time-series-in-pandas?ex=7).\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Read the file `'GDP.csv'` into a DataFrame called `gdp`, using `parse_dates=True` and `index_col='DATE'`.\n",
    "- Create a DataFrame `post2008` by slicing `gdp` such that it comprises all rows from 2008 onward.\n",
    "- Print the last 8 rows of the slice `post2008`. This has been done for you. This data has quarterly frequency so the indices are separated by three-month intervals.\n",
    "- Create the DataFrame `yearly` by resampling the slice `post2008` by year. Remember, you need to chain `.resample()` (using the alias `'A'` for annual frequency) with some kind of aggregation; you will use the aggregation method `.last()` to select the last element when resampling.\n",
    "- Compute the percentage growth of the resampled DataFrame `yearly` with `.pct_change() * 100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              VALUE\n",
      "DATE               \n",
      "2014-07-01  17569.4\n",
      "2014-10-01  17692.2\n",
      "2015-01-01  17783.6\n",
      "2015-04-01  17998.3\n",
      "2015-07-01  18141.9\n",
      "2015-10-01  18222.8\n",
      "2016-01-01  18281.6\n",
      "2016-04-01  18436.5\n",
      "              VALUE\n",
      "DATE               \n",
      "2008-12-31  14549.9\n",
      "2009-12-31  14566.5\n",
      "2010-12-31  15230.2\n",
      "2011-12-31  15785.3\n",
      "2012-12-31  16297.3\n",
      "2013-12-31  16999.9\n",
      "2014-12-31  17692.2\n",
      "2015-12-31  18222.8\n",
      "2016-12-31  18436.5\n",
      "              VALUE    growth\n",
      "DATE                         \n",
      "2008-12-31  14549.9       NaN\n",
      "2009-12-31  14566.5  0.114090\n",
      "2010-12-31  15230.2  4.556345\n",
      "2011-12-31  15785.3  3.644732\n",
      "2012-12-31  16297.3  3.243524\n",
      "2013-12-31  16999.9  4.311144\n",
      "2014-12-31  17692.2  4.072377\n",
      "2015-12-31  18222.8  2.999062\n",
      "2016-12-31  18436.5  1.172707\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# Read 'GDP.csv' into a DataFrame: gdp\n",
    "gdp = pd.read_csv('data/gdp_usa.csv', index_col = 'DATE', parse_dates = True)\n",
    "\n",
    "# Slice all the gdp data from 2008 onward: post2008\n",
    "post2008 = gdp.loc['2008':, :]\n",
    "\n",
    "# Print the last 8 rows of post2008\n",
    "print(post2008.tail(8))\n",
    "\n",
    "# Resample post2008 by year, keeping last(): yearly\n",
    "yearly = post2008.resample('A').last()\n",
    "\n",
    "# Print yearly (now it is yearly)\n",
    "print(yearly)\n",
    "\n",
    "# Compute percentage growth of yearly: yearly['growth']\n",
    "yearly['growth'] = yearly.pct_change() * 100\n",
    "\n",
    "# Print yearly again\n",
    "print(yearly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to question, let's find the maximum year where the `growth` was maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n"
     ]
    }
   ],
   "source": [
    "# get the DateTime object and access its year\n",
    "print(yearly['growth'].idxmax().year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense. After 2008 economic crisis, GDP went into a deep dive returning higher growth rate in the following years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting currency of stocks\n",
    "\n",
    "In this exercise, stock prices in US Dollars for the S&P 500 in 2015 have been obtained from [Yahoo Finance](https://finance.yahoo.com/). The files `sp500.csv` for sp500 and `exchange.csv` for the exchange rates are both provided to you.\n",
    "\n",
    "Using the daily exchange rate to Pounds Sterling, your task is to convert both the Open and Close column prices.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Read the DataFrames `sp500` & `exchange` from the files `'sp500.csv'` & `'exchange.csv'` respectively..\n",
    "- Use `parse_dates=True` and `index_col='Date'`.\n",
    "- Extract the columns `'Open'` & `'Close'` from the DataFrame `sp500` as a new DataFrame `dollars` and print the first 5 rows.\n",
    "- Construct a new DataFrame `pounds` by converting US dollars to British pounds. You'll use the `.multiply()` method of `dollars` with `exchange['GBP/USD']` and `axis='rows'`\n",
    "- Print the first 5 rows of the new DataFrame `pounds`. This has been done for you, so hit 'Submit Answer' to see the results!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open        Close\n",
      "Date                                \n",
      "2015-01-02  2058.899902  2058.199951\n",
      "2015-01-05  2054.439941  2020.579956\n",
      "2015-01-06  2022.150024  2002.609985\n",
      "2015-01-07  2005.550049  2025.900024\n",
      "2015-01-08  2030.609985  2062.139893\n",
      "\n",
      "\n",
      "                   Open        Close\n",
      "Date                                \n",
      "2015-01-02  1340.364425  1339.908750\n",
      "2015-01-05  1348.616555  1326.389506\n",
      "2015-01-06  1332.515980  1319.639876\n",
      "2015-01-07  1330.562125  1344.063112\n",
      "2015-01-08  1343.268811  1364.126161\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# Read 'sp500.csv' into a DataFrame: sp500\n",
    "sp500 = pd.read_csv('data/sp500.csv', index_col = 'Date', parse_dates = True)\n",
    "\n",
    "# Read 'exchange.csv' into a DataFrame: exchange\n",
    "exchange = pd.read_csv('data/exchange.csv', index_col = 'Date', parse_dates = True)\n",
    "\n",
    "# Subset 'Open' & 'Close' columns from sp500: dollars\n",
    "dollars = sp500[['Open', 'Close']]\n",
    "\n",
    "# Print the head of dollars\n",
    "print(dollars.head())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Convert dollars to pounds: pounds\n",
    "pounds = dollars.multiply(exchange['GBP/USD'], axis=0)\n",
    "\n",
    "# Print the head of pounds\n",
    "print(pounds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Concatenating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending Series with nonunique Indices\n",
    "\n",
    "The Series `bronze` and `silver`, which have been printed in the IPython Shell, represent the 5 countries that won the most bronze and silver Olympic medals respectively between 1896 & 2008. The Indexes of both Series are called `Country` and the values are the corresponding number of medals won.\n",
    "\n",
    "If you were to run the command `combined = bronze.append(silver)`, how many rows would `combined` have? And how many rows would `combined.loc['United States']` return? Find out for yourself by running these commands in the IPython Shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Total\n",
      "Country               \n",
      "United States   1052.0\n",
      "Soviet Union     584.0\n",
      "United Kingdom   505.0\n",
      "France           475.0\n",
      "Germany          454.0\n",
      "                 Total\n",
      "Country               \n",
      "United States   1195.0\n",
      "Soviet Union     627.0\n",
      "United Kingdom   591.0\n",
      "France           461.0\n",
      "Germany          350.0\n"
     ]
    }
   ],
   "source": [
    "# first create those dataframes\n",
    "bronze = bronze[['Country', 'Total']].head(5).set_index('Country', drop=True)\n",
    "print(bronze)\n",
    "\n",
    "silver = silver[['Country', 'Total']].head(5).set_index('Country', drop=True)\n",
    "print(silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Total\n",
      "Country               \n",
      "United States   1052.0\n",
      "Soviet Union     584.0\n",
      "United Kingdom   505.0\n",
      "France           475.0\n",
      "Germany          454.0\n",
      "United States   1195.0\n",
      "Soviet Union     627.0\n",
      "United Kingdom   591.0\n",
      "France           461.0\n",
      "Germany          350.0\n",
      "\n",
      "\n",
      "                Total\n",
      "Country              \n",
      "United States  1052.0\n",
      "United States  1195.0\n"
     ]
    }
   ],
   "source": [
    "combined = bronze.append(silver)\n",
    "print(combined)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(combined.loc['United States'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`combined` has 10 rows and `combined.loc['United States']` has 2 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending pandas Series\n",
    "\n",
    "In this exercise, you'll load sales data from the months January, February, and March into DataFrames. Then, you'll extract Series with the `'Units'` column from each and append them together with method chaining using `.append()`.\n",
    "\n",
    "To check that the stacking worked, you'll print slices from these Series, and finally, you'll add the result to figure out the total units sold in the first quarter.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Read the files `'sales-jan-2015.csv'`, `'sales-feb-2015.csv'` and `'sales-mar-2015.csv'` into the DataFrames `jan`, `feb`, and `mar` respectively.\n",
    "- Use `parse_dates=True` and `index_col='Date'`.\n",
    "- Extract the `'Units'` column of `jan`, `feb`, and `mar` to create the Series `jan_units`, `feb_units`, and `mar_units` respectively.\n",
    "- Construct the Series `quarter1` by appending `feb_units` to `jan_units` and then appending `mar_units` to the result. Use chained calls to the `.append()` method to do this.\n",
    "- Verify that `quarter1` has the individual Series stacked vertically. To do this:\n",
    "- Print the slice containing rows from `jan 27, 2015` to `feb 2, 2015`.\n",
    "- Print the slice containing rows from `feb 26, 2015` to `mar 7, 2015`.\n",
    "- Compute and print the total number of units sold from the Series `quarter1`. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2015-01-27 07:11:55    18\n",
      "2015-02-02 08:33:01     3\n",
      "2015-02-02 20:54:49     9\n",
      "Name: Units, dtype: int64\n",
      "\n",
      "\n",
      "Date\n",
      "2015-02-26 08:57:45     4\n",
      "2015-02-26 08:58:51     1\n",
      "2015-03-06 10:11:45    17\n",
      "2015-03-06 02:03:56    17\n",
      "Name: Units, dtype: int64\n",
      "642\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# Load 'sales-jan-2015.csv' into a DataFrame: jan\n",
    "jan = pd.read_csv('data/sales-jan-2015.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Load 'sales-feb-2015.csv' into a DataFrame: feb\n",
    "feb = pd.read_csv('data/sales-feb-2015.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Load 'sales-mar-2015.csv' into a DataFrame: mar\n",
    "mar = pd.read_csv('data/sales-mar-2015.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Extract the 'Units' column from jan: jan_units\n",
    "jan_units = jan['Units']\n",
    "\n",
    "# Extract the 'Units' column from feb: feb_units\n",
    "feb_units = feb['Units']\n",
    "\n",
    "# Extract the 'Units' column from mar: mar_units\n",
    "mar_units = mar['Units']\n",
    "\n",
    "# Append feb_units and then mar_units to jan_units: quarter1\n",
    "quarter1 = jan_units.append(feb_units).append(mar_units)\n",
    "\n",
    "# Print the first slice from quarter1\n",
    "print(quarter1.loc['jan 27, 2015':'feb 2, 2015'])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Print the second slice from quarter1\n",
    "print(quarter1.loc['feb 26, 2015': 'mar 7, 2015'])\n",
    "\n",
    "# Compute & print total sales in quarter1\n",
    "print(quarter1.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating pandas Series along row axis\n",
    "\n",
    "Having learned how to append Series, you'll now learn how to achieve the same result by concatenating Series instead. You'll continue to work with the sales data you've seen previously. This time, the DataFrames `jan`, `feb`, and `mar` have been pre-loaded.\n",
    "\n",
    "Your job is to use `pd.concat()` with a list of Series to achieve the same result that you would get by chaining calls to `.append()`.\n",
    "\n",
    "You may be wondering about the difference between `pd.concat()` and pandas' `.append()` method. One way to think of the difference is that `.append()` is a specific case of a concatenation, while `pd.concat()` gives you more flexibility, as you'll see in later exercises.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Create an empty list called `units`. This has been done for you.\n",
    "- Use a `for` loop to iterate over `[jan, feb, mar]`:\n",
    "    - In each iteration of the loop, append the 'Units' column of each DataFrame to units.\n",
    "- Concatenate the Series contained in the list units into a longer Series called quarter1 using pd.concat().\n",
    "    - Specify the keyword argument axis='rows' to stack the Series vertically.\n",
    "- Verify that `quarter1` has the individual Series stacked vertically by printing slices. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2015-01-27 07:11:55    18\n",
      "2015-02-02 08:33:01     3\n",
      "2015-02-02 20:54:49     9\n",
      "Name: Units, dtype: int64\n",
      "\n",
      "\n",
      "Date\n",
      "2015-02-26 08:57:45     4\n",
      "2015-02-26 08:58:51     1\n",
      "2015-03-06 10:11:45    17\n",
      "2015-03-06 02:03:56    17\n",
      "Name: Units, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty list: units\n",
    "units = []\n",
    "\n",
    "# Build the list of Series\n",
    "for month in [jan, feb, mar]:\n",
    "    units.append(month['Units'])\n",
    "\n",
    "# Concatenate the list: quarter1\n",
    "quarter1 = pd.concat(units, axis='rows')\n",
    "\n",
    "# Print slices from quarter1\n",
    "print(quarter1.loc['jan 27, 2015':'feb 2, 2015'])\n",
    "print('\\n')\n",
    "print(quarter1.loc['feb 26, 2015':'mar 7, 2015'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending DataFrames with ignore_index\n",
    "\n",
    "In this exercise, you'll use the [Baby Names Dataset](https://www.data.gov/developers/baby-names-dataset/) (from [data.gov](http://data.gov/)) again. This time, both DataFrames `names_1981` and `names_1881` are loaded *without* specifying an Index column (so the default Indexes for both are RangeIndexes).\n",
    "\n",
    "You'll use the DataFrame `.append()` method to make a DataFrame `combined_names`. To distinguish rows from the original two DataFrames, you'll add a `'year'` column to each with the year (1881 or 1981 in this case). In addition, you'll specify `ignore_index=True` so that the index values are not used along the concatenation axis. The resulting axis will instead be labeled `0, 1, ..., n-1`, which is useful if you are concatenating objects where the concatenation axis does not have meaningful indexing information.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Create a `'year'` column in the DataFrames `names_1881` and `names_1981`, with values of `1881` and `1981` respectively. Recall that assigning a scalar value to a DataFrame column broadcasts that value throughout.\n",
    "- Create a new DataFrame called `combined_names` by appending the rows of `names_1981` underneath the rows of `names_1881`. Specify the keyword argument `ignore_index=True` to make a new RangeIndex of unique integers for each row.\n",
    "- Print the shapes of all three DataFrames. This has been done for you.\n",
    "- Extract all rows from `combined_names` that have the name `'Morgan'`. To do this, use the `.loc[]` accessor with an appropriate filter. The relevant column of `combined_names` here is `'name'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19455, 3)\n",
      "(1935, 3)\n",
      "(21390, 3)\n",
      "\n",
      "\n",
      "         name gender  year\n",
      "1283   Morgan      M  1881\n",
      "2096   Morgan      F  1981\n",
      "14390  Morgan      M  1981\n"
     ]
    }
   ],
   "source": [
    "# import the dataset without specifying the index\n",
    "names_1881 = pd.read_csv('data/names1881.csv', header=None, names=['name', 'gender', 'year'])\n",
    "names_1981 = pd.read_csv('data/names1981.csv', header=None, names=['name', 'gender', 'year'])\n",
    "names_1881\n",
    "\n",
    "# Add 'year' column to names_1881 and names_1981\n",
    "names_1881['year'] = 1881\n",
    "names_1981['year'] = 1981\n",
    "\n",
    "# Append names_1981 after names_1881 with ignore_index=True: combined_names\n",
    "combined_names = names_1881.append(names_1981, ignore_index=True)\n",
    "\n",
    "# Print shapes of names_1981, names_1881, and combined_names\n",
    "print(names_1981.shape)\n",
    "print(names_1881.shape)\n",
    "print(combined_names.shape)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Print all rows that contain the name 'Morgan'\n",
    "print(combined_names.loc[combined_names['name'] == 'Morgan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating pandas DataFrames along column axis\n",
    "\n",
    "The function `pd.concat()` can concatenate DataFrames *horizontally* as well as *vertically* (vertical is the default). To make the DataFrames stack horizontally, you have to specify the keyword argument `axis=1` or `axis='columns'`.\n",
    "\n",
    "In this exercise, you'll use weather data with maximum and mean daily temperatures sampled at different rates (quarterly versus monthly). You'll concatenate the rows of both and see that, where rows are missing in the coarser DataFrame, null values are inserted in the concatenated DataFrame. This corresponds to an outer join (which you will explore in more detail in later exercises).\n",
    "\n",
    "The files `'quarterly_max_temp.csv'` and `'monthly_mean_temp.csv'` have been pre-loaded into the DataFrames `weather_max` and `weather_mean` respectively, and `pandas` has been imported as `pd`.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Create `weather_list`, a list of the DataFrames `weather_max` and `weather_mean`.\n",
    "- Create a new DataFrame called `weather` by concatenating `weather_list` *horizontally*.\n",
    "    - Pass the list to `pd.concat()` and specify the keyword argument `axis=1` to stack them horizontally.\n",
    "- Print the new DataFrame `weather`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max TemperatureF</th>\n",
       "      <th>Mean TemperatureF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-31</th>\n",
       "      <td>68</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-28</th>\n",
       "      <td>60</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Max TemperatureF  Mean TemperatureF\n",
       "Date                                           \n",
       "2013-01-31                68                 62\n",
       "2013-02-28                60                 48"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's import the dataset\n",
    "weather2 = weather[['Max TemperatureF', 'Mean TemperatureF']].resample('m').max()\n",
    "weather2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max TemperatureF</th>\n",
       "      <th>Mean TemperatureF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jan</th>\n",
       "      <td>68</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb</th>\n",
       "      <td>60</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Max TemperatureF  Mean TemperatureF\n",
       "Month                                     \n",
       "Jan                  68                 62\n",
       "Feb                  60                 48"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only get locale's abbreviated month name\n",
    "weather2.index = weather2.index.strftime('%b')\n",
    "weather2.index.name = 'Month'\n",
    "weather2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get the example dataframes\n",
    "weather_max = weather2.loc[['Jan', 'Apr', 'Jul', 'Oct'], 'Max TemperatureF']\n",
    "weather_mean = weather2.loc[:, 'Mean TemperatureF'].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Max TemperatureF  Mean TemperatureF\n",
      "Jan              68.0                 62\n",
      "Apr              84.0                 72\n",
      "Jul              91.0                 80\n",
      "Oct              84.0                 74\n",
      "Aug               NaN                 77\n",
      "Dec               NaN                 62\n",
      "Feb               NaN                 48\n",
      "Jun               NaN                 78\n",
      "Mar               NaN                 55\n",
      "May               NaN                 77\n",
      "Nov               NaN                 60\n",
      "Sep               NaN                 79\n"
     ]
    }
   ],
   "source": [
    "# Create a list of weather_max and weather_mean\n",
    "weather_list = [weather_max, weather_mean]\n",
    "\n",
    "# Concatenate weather_list horizontally\n",
    "weather = pd.concat(weather_list, axis=1, sort=False)\n",
    "\n",
    "# Print weather\n",
    "print(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading multiple files to build a DataFrame\n",
    "\n",
    "It is often convenient to build a large DataFrame by parsing many files as DataFrames and concatenating them all at once. You'll do this here with three files, but, in principle, this approach can be used to combine data from dozens or hundreds of files.\n",
    "\n",
    "Here, you'll work with DataFrames compiled from [The Guardian's Olympic medal dataset](https://www.theguardian.com/sport/datablog/2012/jun/25/olympic-medal-winner-list-data).\n",
    "\n",
    "`pandas` has been imported as `pd` and the list `medal_types` has been pre-loaded for you, which contains the strings `'bronze'`, `'silver'`, and `'gold'`.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Iterate over `medal_types` in the `for` loop.\n",
    "- Inside the `for` loop:\n",
    "    - Create `file_name` using string interpolation with the loop variable `medal`. This has been done for you. The expression `\"%s_top5.csv\" % medal` evaluates as a string with the *value* of `medal` replacing `%s` in the format string.\n",
    "    - Create the list of column names called `columns`. This has been done for you.\n",
    "    - Read `file_name` into a DataFrame called `medal_df`. Specify the keyword arguments `header=0`, `index_col='Country'`, and `names=columns` to get the correct row and column Indexes.\n",
    "- Append `medal_df` to `medals` using the list `.append()` method.\n",
    "- Concatenate the list of DataFrames `medals` horizontally (using `axis='columns'`) to create a single DataFrame called `medals_df`. Print it in its entirety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                bronze  silver    gold\n",
      "United States   1052.0  1195.0  2088.0\n",
      "Soviet Union     584.0   627.0   838.0\n",
      "United Kingdom   505.0   591.0   498.0\n",
      "France           475.0   461.0     NaN\n",
      "Germany          454.0     NaN   407.0\n",
      "Italy              NaN   394.0   460.0\n"
     ]
    }
   ],
   "source": [
    "medal_types = ['bronze', 'silver', 'gold']\n",
    "\n",
    "#Initialize an empyy list: medals\n",
    "medals =[]\n",
    "\n",
    "for medal in medal_types:\n",
    "    # Create the file name: file_name\n",
    "    file_name = \"data/%s_top5.csv\" % medal  # regex here\n",
    "    # Create list of column names: columns\n",
    "    columns = ['Country', medal]\n",
    "    # Read file_name into a DataFrame: medal_df\n",
    "    medal_df = pd.read_csv(file_name, header=0, index_col='Country', names=columns)\n",
    "    # Append medal_df to medals\n",
    "    medals.append(medal_df)\n",
    "\n",
    "# Concatenate medals horizontally: medals_df\n",
    "medals_df = pd.concat(medals, axis='columns', sort=False)\n",
    "\n",
    "# Print medals_df\n",
    "print(medals_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating vertically to get MultiIndexed rows\n",
    "\n",
    "When stacking a sequence of DataFrames vertically, it is sometimes desirable to construct a MultiIndex to indicate the DataFrame from which each row originated. This can be done by specifying the `keys` parameter in the call to `pd.concat()`, which generates a hierarchical index with the labels from `keys` as the outermost index label. So you don't have to rename the columns of each DataFrame as you load it. Instead, only the Index column needs to be specified.\n",
    "\n",
    "Here, you'll continue working with DataFrames compiled from [The Guardian's Olympic medal dataset](https://www.theguardian.com/sport/datablog/2012/jun/25/olympic-medal-winner-list-data). Once again, `pandas` has been imported as `pd` and two lists have been pre-loaded: An empty list called `medals`, and `medal_types`, which contains the strings `'bronze'`, `'silver'`, and `'gold'`.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Within the `for` loop:\n",
    "    - Read `file_name` into a DataFrame called `medal_df`. Specify the index to be `'Country'`.\n",
    "    - Append `medal_df` to `medals`.\n",
    "- Concatenate the list of DataFrames `medals` into a single DataFrame called `medals`. Be sure to use the keyword argument `keys=['bronze', 'silver', 'gold']` to create a vertically stacked DataFrame with a MultiIndex.\n",
    "- Print the new DataFrame `medals`. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Total\n",
      "       Country               \n",
      "bronze United States   1052.0\n",
      "       Soviet Union     584.0\n",
      "       United Kingdom   505.0\n",
      "       France           475.0\n",
      "       Germany          454.0\n",
      "silver United States   1195.0\n",
      "       Soviet Union     627.0\n",
      "       United Kingdom   591.0\n",
      "       France           461.0\n",
      "       Italy            394.0\n",
      "gold   United States   2088.0\n",
      "       Soviet Union     838.0\n",
      "       United Kingdom   498.0\n",
      "       Italy            460.0\n",
      "       Germany          407.0\n"
     ]
    }
   ],
   "source": [
    "medals = []\n",
    "\n",
    "for medal in medal_types:\n",
    "\n",
    "    file_name = \"data/%s_top5.csv\" % medal\n",
    "    \n",
    "    # Read file_name into a DataFrame: medal_df\n",
    "    medal_df = pd.read_csv(file_name, index_col='Country')\n",
    "    \n",
    "    # Append medal_df to medals\n",
    "    medals.append(medal_df)\n",
    "    \n",
    "# Concatenate medals: medals\n",
    "medals = pd.concat(medals, keys=['bronze', 'silver', 'gold'])\n",
    "\n",
    "# Print medals in entirety\n",
    "print(medals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing MultiIndexed DataFrames\n",
    "\n",
    "This exercise picks up where the last ended (again using [The Guardian's Olympic medal dataset](https://www.theguardian.com/sport/datablog/2012/jun/25/olympic-medal-winner-list-data)).\n",
    "\n",
    "You are provided with the MultiIndexed DataFrame as produced at the end of the preceding exercise. Your task is to sort the DataFrame and to use the `pd.IndexSlice` to extract specific slices. Check out [this exercise](https://campus.datacamp.com/courses/manipulating-dataframes-with-pandas/advanced-indexing?ex=10) from Manipulating DataFrames with pandas to refresh your memory on how to deal with MultiIndexed DataFrames.\n",
    "\n",
    "`pandas` has been imported for you as `pd` and the DataFrame `medals` is already in your namespace.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Create a new DataFrame `medals_sorted` with the entries of `medals` sorted. Use `.sort_index(level=0)` to ensure the Index is sorted suitably.\n",
    "- Print the number of bronze medals won by Germany and all of the silver medal data. This has been done for you.\n",
    "- Create an alias for `pd.IndexSlice` called `idx`. A *slicer* `pd.IndexSlice` is required when slicing on the *inner* level of a MultiIndex.\n",
    "- Slice all the data on medals won by the United Kingdom in the DataFrame `medals_sorted`. To do this, use the `.loc[]` accessor with `idx[:,'United Kingdom'], :`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total    454.0\n",
      "Name: (bronze, Germany), dtype: float64\n",
      "                 Total\n",
      "Country               \n",
      "France           461.0\n",
      "Italy            394.0\n",
      "Soviet Union     627.0\n",
      "United Kingdom   591.0\n",
      "United States   1195.0\n",
      "                       Total\n",
      "       Country              \n",
      "bronze United Kingdom  505.0\n",
      "gold   United Kingdom  498.0\n",
      "silver United Kingdom  591.0\n"
     ]
    }
   ],
   "source": [
    "# Sort the entries of medals: medals_sorted\n",
    "medals_sorted = medals.sort_index(level=0)\n",
    "\n",
    "# Print the number of Bronze medals won by Germany\n",
    "print(medals_sorted.loc[('bronze','Germany')])\n",
    "\n",
    "# Print data about silver medals\n",
    "print(medals_sorted.loc['silver'])\n",
    "\n",
    "# Create alias for pd.IndexSlice: idx\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# Print all the data on medals won by the United Kingdom\n",
    "print(medals_sorted.loc[idx[:, 'United Kingdom'], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bronze</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silver</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>591.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Total\n",
       "       Country              \n",
       "bronze United Kingdom  505.0\n",
       "gold   United Kingdom  498.0\n",
       "silver United Kingdom  591.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or we can use. It will give the same result.\n",
    "medals_sorted.loc[(slice(None), 'United Kingdom'), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating horizontally to get MultiIndexed columns\n",
    "\n",
    "It is also possible to construct a DataFrame with hierarchically indexed columns. For this exercise, you'll start with pandas imported and a list of three DataFrames called `dataframes`. All three DataFrames contain `'Company'`, `'Product'`, and `'Units'` columns with a `'Date'` column as the index pertaining to sales transactions during the month of February, 2015. The first DataFrame describes `Hardware` transactions, the second describes `Software` transactions, and the third, `Service` transactions.\n",
    "\n",
    "Your task is to concatenate the DataFrames horizontally and to create a MultiIndex on the columns. From there, you can summarize the resulting DataFrame and slice some information from it.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Construct a new DataFrame `february` with MultiIndexed columns by concatenating the list `dataframes`.\n",
    "- Use `axis=1` to stack the DataFrames horizontally and the keyword argument `keys=['Hardware', 'Software', 'Service']` to construct a hierarchical Index from each DataFrame.\n",
    "- Print summary information from the new DataFrame `february` using the `.info()` method. This has been done for you.\n",
    "- Create an alias called `idx` for `pd.IndexSlice`.\n",
    "- Extract a slice called `slice_2_8` from `february` (using `.loc[]` & `idx`) that comprises rows between Feb. 2, 2015 to Feb. 8, 2015 from columns under `'Company'`.\n",
    "- Print the `slice_2_8`. This has been done for you, so hit 'Submit Answer' to see the sliced data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "file_paths = glob('data/feb*.csv')\n",
    "\n",
    "# create empty list to append the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# append\n",
    "for path in file_paths:\n",
    "    dataframes.append(pd.read_csv(path, index_col='Date', parse_dates=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 20 entries, 2015-02-02 08:33:01 to 2015-02-26 08:58:51\n",
      "Data columns (total 9 columns):\n",
      "(Hardware, Company)    5 non-null object\n",
      "(Hardware, Product)    5 non-null object\n",
      "(Hardware, Units)      5 non-null float64\n",
      "(Software, Company)    6 non-null object\n",
      "(Software, Product)    6 non-null object\n",
      "(Software, Units)      6 non-null float64\n",
      "(Service, Company)     9 non-null object\n",
      "(Service, Product)     9 non-null object\n",
      "(Service, Units)       9 non-null float64\n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 1.6+ KB\n",
      "None\n",
      "\n",
      "\n",
      "                            Hardware Software          Service\n",
      "                             Company  Company          Company\n",
      "Date                                                          \n",
      "2015-02-02 08:33:01              NaN      NaN            Hooli\n",
      "2015-02-02 20:54:49        Mediacore      NaN              NaN\n",
      "2015-02-03 14:14:18              NaN      NaN          Initech\n",
      "2015-02-04 15:36:29              NaN      NaN        Streeplex\n",
      "2015-02-04 21:52:45  Acme Coporation      NaN              NaN\n",
      "2015-02-05 01:53:06              NaN      NaN  Acme Coporation\n",
      "2015-02-05 22:05:03              NaN    Hooli              NaN\n",
      "2015-02-07 22:58:10  Acme Coporation      NaN              NaN\n"
     ]
    }
   ],
   "source": [
    "# Concatenate dataframes: february\n",
    "february = pd.concat(dataframes, axis=1, keys=['Hardware', 'Software', 'Service'])\n",
    "\n",
    "# Print february.info()\n",
    "print(february.info())\n",
    "\n",
    "# Assign pd.IndexSlice: idx\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Create the slice: slice_2_8\n",
    "slice_2_8 = february.loc['2015-02-02':'2015-02-08', idx[:, 'Company']]\n",
    "\n",
    "# Print slice_2_8\n",
    "print(slice_2_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating DataFrames from a dict\n",
    "\n",
    "You're now going to revisit the sales data you worked with earlier in the chapter. Three DataFrames `jan`, `feb`, and `mar` have been pre-loaded for you. Your task is to aggregate the sum of all sales over the `'Company'` column into a single DataFrame. You'll do this by constructing a dictionary of these DataFrames and then concatenating them.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Create a list called `month_list` consisting of the tuples `('january', jan)`, `('february', feb)`, and `('march', mar)`.\n",
    "- Create an empty dictionary called `month_dict`.\n",
    "- Inside the `for` loop:\n",
    "    - Group `month_data` by `'Company'` and use `.sum()` to aggregate.\n",
    "- Construct a new DataFrame called `sales` by concatenating the DataFrames stored in `month_dict`.\n",
    "- Create an alias for `pd.IndexSlic`e and print all sales by `'Mediacore'`. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Units\n",
      "         Company               \n",
      "january  Acme Coporation     76\n",
      "         Hooli               70\n",
      "         Initech             37\n",
      "         Mediacore           15\n",
      "         Streeplex           50\n",
      "february Acme Coporation     34\n",
      "         Hooli               30\n",
      "         Initech             30\n",
      "         Mediacore           45\n",
      "         Streeplex           37\n",
      "march    Acme Coporation      5\n",
      "         Hooli               37\n",
      "         Initech             68\n",
      "         Mediacore           68\n",
      "         Streeplex           40\n",
      "                    Units\n",
      "         Company         \n",
      "january  Mediacore     15\n",
      "february Mediacore     45\n",
      "march    Mediacore     68\n"
     ]
    }
   ],
   "source": [
    "# Make the list of tuples: month_list\n",
    "month_list = [('january', jan), ('february', feb), ('march', mar)]\n",
    "\n",
    "# Create an empty dictionary: month_dict\n",
    "month_dict = dict()\n",
    "\n",
    "for month_name, month_data in month_list:\n",
    "\n",
    "    # Group month_data: month_dict[month_name]\n",
    "    month_dict[month_name] = month_data.groupby('Company').sum()\n",
    "\n",
    "# Concatenate data in month_dict: sales\n",
    "sales = pd.concat(month_dict)\n",
    "\n",
    "# Print sales\n",
    "print(sales)\n",
    "\n",
    "# Print all sales by Mediacore\n",
    "idx = pd.IndexSlice\n",
    "print(sales.loc[idx[:, 'Mediacore'], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> \n",
    "\n",
    "We are creating that `month_list` so we can do tuple unpacking in a `for` loop.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating DataFrames with inner join\n",
    "\n",
    "Here, you'll continue working with DataFrames compiled from [The Guardian's Olympic medal dataset](https://www.theguardian.com/sport/datablog/2012/jun/25/olympic-medal-winner-list-data).\n",
    "\n",
    "The DataFrames `bronze`, `silver`, and `gold` have been pre-loaded for you.\n",
    "\n",
    "Your task is to compute an *inner join*.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Construct a list of DataFrames called `medal_list` with entries `bronze`, `silver`, and `gold`.\n",
    "- Concatenate `medal_list` horizontally with an *inner join* to create `medals`.\n",
    "    - Use the keyword argument `keys=['bronze', 'silver', 'gold']` to yield suitable hierarchical indexing.\n",
    "    - Use `axis=1` to get horizontal concatenation.\n",
    "    - Use `join='inner'` to keep only rows that share common index labels.\n",
    "- Print the new DataFrame `medals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                bronze  silver    gold\n",
      "                 Total   Total   Total\n",
      "Country                               \n",
      "United States   1052.0  1195.0  2088.0\n",
      "Soviet Union     584.0   627.0   838.0\n",
      "United Kingdom   505.0   591.0   498.0\n",
      "France           475.0   461.0   378.0\n",
      "Germany          454.0   350.0   407.0\n"
     ]
    }
   ],
   "source": [
    "# bronze and silver are in format, gold needs to be fixed\n",
    "gold = gold.set_index('Country', drop=True).drop('NOC', axis=1)\n",
    "\n",
    "# Create the list of DataFrames: medal_list\n",
    "medal_list = [bronze, silver, gold]\n",
    "\n",
    "# Concatenate medal_list horizontally using an inner join: medals\n",
    "medals = pd.concat(medal_list, keys=['bronze', 'silver', 'gold'], axis=1, join='inner')\n",
    "\n",
    "# Print medals\n",
    "print(medals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "France, Italy, and Germany got dropped as part of the join since they are not present in each of `bronze`, `silver`, and `gold`. Therefore, the final DataFrame has only the United States, Soviet Union, and United Kingdom.\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling & concatenating DataFrames with inner join\n",
    "\n",
    "In this exercise, you'll compare the historical 10-year GDP (Gross Domestic Product) growth in the US and in China. The data for the US starts in 1947 and is recorded quarterly; by contrast, the data for China starts in 1961 and is recorded annually.\n",
    "\n",
    "You'll need to use a combination of resampling and an inner join to align the index labels. You'll need an appropriate [offset alias](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases) for resampling, and the method `.resample()` must be chained with some kind of aggregation method (`.pct_change()` and `.last()` in this case).\n",
    "\n",
    "`pandas` has been imported as `pd`, and the DataFrames `china` and `us` have been pre-loaded, with the output of `china.head()` and `us.head()` printed in the IPython Shell.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Make a new DataFrame `china_annual` by resampling the DataFrame `china` with `.resample('A').last()` (i.e., with *annual* frequency) and chaining two method calls:\n",
    "- Chain `.pct_change(10)` as an aggregation method to compute the percentage change with an offset of ten years.\n",
    "- Chain `.dropna()` to eliminate rows containing null values.\n",
    "- Make a new DataFrame `us_annual` by resampling the DataFrame `us` exactly as you resampled `china`.\n",
    "- Concatenate `china_annual` and `us_annual` to construct a DataFrame called `gdp`. Use `join='inner'` to perform an *inner* join and use `axis=1` to concatenate *horizontally*.\n",
    "- Print the result of resampling `gdp` every decade (i.e., using `.resample('10A')`) and aggregating with the method `.last()`. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the datasets\n",
    "china = pd.read_csv('data/gdp_china.csv', index_col='Year', parse_dates=True)\n",
    "china.columns = ['China']\n",
    "us = pd.read_csv('data/gdp_usa.csv', index_col='DATE', parse_dates=True)\n",
    "us.columns = ['US']\n",
    "us.index.name='Year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               China        US\n",
      "Year                          \n",
      "1971-12-31  0.988860  1.052270\n",
      "1981-12-31  0.972048  1.750922\n",
      "1991-12-31  0.962528  0.912380\n",
      "2001-12-31  2.492511  0.704219\n",
      "2011-12-31  4.623958  0.475082\n",
      "2021-12-31  3.789936  0.361780\n"
     ]
    }
   ],
   "source": [
    "# Resample and tidy china: china_annual\n",
    "china_annual = china.resample('A').last().pct_change(10).dropna()\n",
    "\n",
    "# Resample and tidy us: us_annual\n",
    "us_annual = us.resample('A').last().pct_change(10).dropna()\n",
    "\n",
    "# Concatenate china_annual and us_annual: gdp\n",
    "gdp = pd.concat([china_annual, us_annual], axis=1, join='inner')\n",
    "\n",
    "# Resample gdp and print\n",
    "print(gdp.resample('10A').last())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like `.rolling()` method, the argument inside `.pct_change(x)` takes the percentage change in the periods of `x` days/months/years. The keyword for that is `.pct_change(periods=10)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Merging data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging company DataFrames\n",
    "\n",
    "Suppose your company has operations in several different cities under several different managers. The DataFrames `revenue` and `managers` contain partial information related to the company. That is, the rows of the `city` columns don't quite match in `revenue` and `managers` (the Mendocino branch has no revenue yet since it just opened and the manager of Springfield branch recently left the company).\n",
    "\n",
    "The DataFrames have been printed in the IPython Shell. If you were to run the command `combined = pd.merge(revenue, managers, on='city')`, how many rows would `combined` have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          city  revenue\n",
      "0       Austin      100\n",
      "1       Denver       83\n",
      "2  Springfield        4\n",
      "\n",
      "\n",
      "        city   manager\n",
      "0     Austin  Charlers\n",
      "1     Denver      Joel\n",
      "2  Mendocino     Brett\n"
     ]
    }
   ],
   "source": [
    "revenue_dict = {'city': {0: 'Austin', 1: 'Denver', 2: 'Springfield'},\n",
    " 'revenue': {0: 100, 1: 83, 2: 4}}\n",
    "managers_dict = {'city': {0: 'Austin', 1: 'Denver', 2: 'Mendocino'},\n",
    " 'manager': {0: 'Charlers', 1: 'Joel', 2: 'Brett'}}\n",
    "\n",
    "revenue = pd.DataFrame(revenue_dict)\n",
    "managers = pd.DataFrame(managers_dict)\n",
    "\n",
    "print(revenue)\n",
    "print('\\n')\n",
    "print(managers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>revenue</th>\n",
       "      <th>manager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austin</td>\n",
       "      <td>100</td>\n",
       "      <td>Charlers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denver</td>\n",
       "      <td>83</td>\n",
       "      <td>Joel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city  revenue   manager\n",
       "0  Austin      100  Charlers\n",
       "1  Denver       83      Joel"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = pd.merge(revenue, managers, on='city')\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Note:</b> \n",
    "\n",
    "Since the default strategy for `pd.merge()` is an *inner join*, `combined` will have 2 rows.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging on a specific column\n",
    "\n",
    "This exercise follows on the last one with the DataFrames `revenue` and `managers` for your company. You expect your company to grow and, eventually, to operate in cities with the same name on different states. As such, you decide that every branch should have a numerical branch identifier. Thus, you add a `branch_id` column to both DataFrames. Moreover, new cities have been added to both the `revenue` and `managers` DataFrames as well. `pandas` has been imported as `pd` and both DataFrames are available in your namespace.\n",
    "\n",
    "At present, there should be a 1-to-1 relationship between the `city` and `branch_id` fields. In that case, the result of a merge on the `city` columns ought to give you the same output as a merge on the `branch_id` columns. Do they? Can you spot an ambiguity in one of the DataFrames?\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Using `pd.merge()`, merge the DataFrames `revenue` and `managers` on the `'city'` column of each. Store the result as `merge_by_city`.\n",
    "- Print the DataFrame `merge_by_city`. This has been done for you.\n",
    "- Merge the DataFrames `revenue` and `managers` on the `'branch_id'` column of each. Store the result as `merge_by_id`.\n",
    "- Print the DataFrame `merge_by_id`. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataframes\n",
    "managers_dict = {'branch_id': {0: 10, 1: 20, 2: 47, 3: 31},\n",
    " 'city': {0: 'Austin', 1: 'Denver', 2: 'Mendocino', 3: 'Springfield'},\n",
    " 'manager': {0: 'Charles', 1: 'Joel', 2: 'Brett', 3: 'Sally'}}\n",
    "revenue_dict = {'branch_id': {0: 10, 1: 20, 2: 47, 3: 31},\n",
    " 'city': {0: 'Austin', 1: 'Denver', 2: 'Mendocino', 3: 'Springfield'},\n",
    " 'manager': {0: 'Charles', 1: 'Joel', 2: 'Brett', 3: 'Sally'}}\n",
    "\n",
    "managers = pd.DataFrame(managers_dict)\n",
    "revenue = pd.DataFrame(revenue_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   branch_id_x         city manager_x  branch_id_y manager_y\n",
      "0           10       Austin   Charles           10   Charles\n",
      "1           20       Denver      Joel           20      Joel\n",
      "2           47    Mendocino     Brett           47     Brett\n",
      "3           31  Springfield     Sally           31     Sally\n",
      "\n",
      "\n",
      "   branch_id       city_x manager_x       city_y manager_y\n",
      "0         10       Austin   Charles       Austin   Charles\n",
      "1         20       Denver      Joel       Denver      Joel\n",
      "2         47    Mendocino     Brett    Mendocino     Brett\n",
      "3         31  Springfield     Sally  Springfield     Sally\n"
     ]
    }
   ],
   "source": [
    "# Merge revenue with managers on 'city': merge_by_city\n",
    "merge_by_city = pd.merge(revenue, managers, on='city')\n",
    "\n",
    "# Print merge_by_city\n",
    "print(merge_by_city)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Merge revenue with managers on 'branch_id': merge_by_id\n",
    "merge_by_id = pd.merge(revenue, managers, on='branch_id')\n",
    "\n",
    "# Print merge_by_id\n",
    "print(merge_by_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging on columns with non-matching labels\n",
    "\n",
    "You continue working with the `revenue` & `managers` DataFrames from before. This time, someone has changed the field name `'city'` to `'branch'` in the `managers` table. Now, when you attempt to merge DataFrames, an exception is thrown:\n",
    "\n",
    "> `pd.merge(revenue, managers, on='city')\n",
    "Traceback (most recent call last):\n",
    "    ... <text deleted> ...\n",
    "    pd.merge(revenue, managers, on='city')\n",
    "    ... <text deleted> ...\n",
    "KeyError: 'city'`\n",
    "\n",
    "Given this, it will take a bit more work for you to join or merge on the city/branch name. You have to specify the `left_on` and `right_on` parameters in the call to `pd.merge()`.\n",
    "\n",
    "As before, `pandas` has been pre-imported as `pd` and the `revenue` and `managers` DataFrames are in your namespace. They have been printed in the IPython Shell so you can examine the columns prior to merging.\n",
    "\n",
    "Are you able to merge better than in the last exercise? How should the rows with `Springfield` be handled?\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Merge the DataFrames `revenue` and `managers` into a single DataFrame called `combined` using the `'city'` and `'branch'` columns from the appropriate DataFrames.\n",
    "    - In your call to `pd.merge()`, you will have to specify the parameters `left_on` and `right_on` appropriately.\n",
    "- Print the new DataFrame `combined`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>branch_id_x</th>\n",
       "      <th>city</th>\n",
       "      <th>revenue</th>\n",
       "      <th>state_x</th>\n",
       "      <th>branch</th>\n",
       "      <th>branch_id_y</th>\n",
       "      <th>manager</th>\n",
       "      <th>state_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Austin</td>\n",
       "      <td>100</td>\n",
       "      <td>TX</td>\n",
       "      <td>Austin</td>\n",
       "      <td>10</td>\n",
       "      <td>Charlers</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>Denver</td>\n",
       "      <td>83</td>\n",
       "      <td>CO</td>\n",
       "      <td>Denver</td>\n",
       "      <td>20</td>\n",
       "      <td>Joel</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>4</td>\n",
       "      <td>IL</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>31</td>\n",
       "      <td>Sally</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>Mendocino</td>\n",
       "      <td>200</td>\n",
       "      <td>CA</td>\n",
       "      <td>Mendocino</td>\n",
       "      <td>47</td>\n",
       "      <td>Brett</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   branch_id_x         city  revenue state_x       branch  branch_id_y  \\\n",
       "0           10       Austin      100      TX       Austin           10   \n",
       "1           20       Denver       83      CO       Denver           20   \n",
       "2           30  Springfield        4      IL  Springfield           31   \n",
       "3           47    Mendocino      200      CA    Mendocino           47   \n",
       "\n",
       "    manager state_y  \n",
       "0  Charlers      TX  \n",
       "1      Joel      CO  \n",
       "2     Sally      MO  \n",
       "3     Brett      CA  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revenue = pd.DataFrame({'branch_id': {0: 10, 1: 20, 2: 30, 3: 47},\n",
    " 'city': {0: 'Austin', 1: 'Denver', 2: 'Springfield', 3: 'Mendocino'},\n",
    " 'revenue': {0: 100, 1: 83, 2: 4, 3: 200},\n",
    " 'state': {0: 'TX', 1: 'CO', 2: 'IL', 3: 'CA'}})\n",
    "\n",
    "managers = pd.DataFrame({'branch': {0: 'Austin', 1: 'Denver', 2: 'Mendocino', 3: 'Springfield'},\n",
    " 'branch_id': {0: 10, 1: 20, 2: 47, 3: 31},\n",
    " 'manager': {0: 'Charlers', 1: 'Joel', 2: 'Brett', 3: 'Sally'},\n",
    " 'state': {0: 'TX', 1: 'CO', 2: 'CA', 3: 'MO'}})\n",
    "\n",
    "# Merge revenue & managers on 'city' & 'branch': combined\n",
    "combined = pd.merge(revenue, managers, left_on='city', right_on='branch')\n",
    "\n",
    "# Print combined\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging on multiple columns\n",
    "\n",
    "Another strategy to disambiguate cities with identical names is to add information on the *states* in which the cities are located. To this end, you add a column called `state` to both DataFrames from the preceding exercises. Again, `pandas` has been pre-imported as `pd` and the `revenue` and `managers` DataFrames are in your namespace.\n",
    "\n",
    "Your goal in this exercise is to use `pd.merge()` to merge DataFrames using multiple columns (using `'branch_id'`, `'city'`, and `'state'` in this case).\n",
    "\n",
    "Are you able to match all your company's branches correctly?\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Create a column called `'state'` in the DataFrame `revenue`, consisting of the list `['TX','CO','IL','CA']`.\n",
    "- Create a column called `'state'` in the DataFrame `managers`, consisting of the list `['TX','CO','CA','MO']`.\n",
    "- Merge the DataFrames `revenue` and `managers` using *three* columns :`'branch_id'`, `'city'`, and `'state'`. Pass them in as a list to the `on` paramater of `pd.merge()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   branch_id       city  revenue state   manager\n",
      "0         10     Austin      100    TX  Charlers\n",
      "1         20     Denver       83    CO      Joel\n",
      "2         47  Mendocino      200    CA     Brett\n"
     ]
    }
   ],
   "source": [
    "revenue = pd.DataFrame({'branch_id': {0: 10, 1: 20, 2: 30, 3: 47},\n",
    " 'city': {0: 'Austin', 1: 'Denver', 2: 'Springfield', 3: 'Mendocino'},\n",
    " 'revenue': {0: 100, 1: 83, 2: 4, 3: 200}})\n",
    "managers = pd.DataFrame({'branch_id': {0: 10, 1: 20, 2: 47, 3: 31},\n",
    " 'city': {0: 'Austin', 1: 'Denver', 2: 'Mendocino', 3: 'Springfield'},\n",
    " 'manager': {0: 'Charlers', 1: 'Joel', 2: 'Brett', 3: 'Sally'}})\n",
    "\n",
    "# Add 'state' column to revenue: revenue['state']\n",
    "revenue['state'] = ['TX','CO','IL','CA']\n",
    "\n",
    "# Add 'state' column to managers: managers['state']\n",
    "managers['state'] = ['TX','CO','CA','MO']\n",
    "\n",
    "# Merge revenue & managers on 'branch_id', 'city', & 'state': combined\n",
    "combined = pd.merge(revenue, managers, on=['branch_id', 'city', 'state'])\n",
    "\n",
    "# Print combined\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left & right merging on multiple columns\n",
    "\n",
    "You now have, in addition to the `revenue` and `managers` DataFrames from prior exercises, a DataFrame `sales` that summarizes units sold from specific branches (identified by `city` and `state` but not `branch_id`).\n",
    "\n",
    "Once again, the `managers` DataFrame uses the label `branch` in place of `city` as in the other two DataFrames. Your task here is to employ *left* and *right* merges to preserve data and identify where data is missing.\n",
    "\n",
    "By merging `revenue` and `sales` with a *right* merge, you can identify the missing `revenue` values. Here, you don't need to specify `left_on` or `right_on` because the columns to merge on have matching labels.\n",
    "\n",
    "By merging `sales` and `managers` with a *left* merge, you can identify the missing `manager`. Here, the columns to merge on have conflicting labels, so you must specify `left_on` and `right_on`. In both cases, you're looking to figure out how to connect the fields in rows containing `Springfield`.\n",
    "\n",
    "`pandas` has been imported as `pd` and the three DataFrames `revenue`, `managers`, and `sales` have been pre-loaded. They have been printed for you to explore in the IPython Shell.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Execute a right merge using `pd.merge()` with `revenue` and `sales` to yield a new DataFrame `revenue_and_sales`.\n",
    "    - Use `how='right'` and `on=['city', 'state']`.\n",
    "- Print the new DataFrame `revenue_and_sales`. This has been done for you.\n",
    "- Execute a left merge with `sales` and `managers` to yield a new DataFrame `sales_and_managers`.\n",
    "    - Use `how='left'`, `left_on=['city', 'state']`, and `right_on=['branch', 'state']`.\n",
    "- Print the new DataFrame `sales_and_managers`. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   branch_id         city  revenue state  units\n",
      "0       10.0       Austin    100.0    TX      2\n",
      "1       20.0       Denver     83.0    CO      4\n",
      "2       30.0  Springfield      4.0    IL      1\n",
      "3       47.0    Mendocino    200.0    CA      1\n",
      "4        NaN  Springfield      NaN    MO      5\n",
      "\n",
      "\n",
      "          city state  units  branch_id       branch   manager\n",
      "0    Mendocino    CA      1       47.0    Mendocino     Brett\n",
      "1       Denver    CO      4       20.0       Denver      Joel\n",
      "2       Austin    TX      2       10.0       Austin  Charlers\n",
      "3  Springfield    MO      5       31.0  Springfield     Sally\n",
      "4  Springfield    IL      1        NaN          NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "sales = pd.DataFrame({'city': {0: 'Mendocino',\n",
    "  1: 'Denver',\n",
    "  2: 'Austin',\n",
    "  3: 'Springfield',\n",
    "  4: 'Springfield'},\n",
    " 'state': {0: 'CA', 1: 'CO', 2: 'TX', 3: 'MO', 4: 'IL'},\n",
    " 'units': {0: 1, 1: 4, 2: 2, 3: 5, 4: 1}})\n",
    "managers.columns = ['branch_id', 'branch', 'manager', 'state']\n",
    "\n",
    "# Merge revenue and sales: revenue_and_sales\n",
    "revenue_and_sales = pd.merge(revenue, sales, how='right', on=['city', 'state'])\n",
    "\n",
    "# Print revenue_and_sales\n",
    "print(revenue_and_sales)\n",
    "\n",
    "# Merge sales and managers: sales_and_managers\n",
    "sales_and_managers = pd.merge(sales, managers, how='left', \\\n",
    "                              left_on=['city', 'state'], right_on=['branch', 'state'])\n",
    "print('\\n')\n",
    "\n",
    "# Print sales_and_managers\n",
    "print(sales_and_managers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging DataFrames with outer join\n",
    "\n",
    "This exercise picks up where the previous one left off. The DataFrames `revenue`, `managers`, and `sales` are pre-loaded into your namespace (and, of course, `pandas` is imported as `pd`). Moreover, the merged DataFrames `revenue_and_sales` and `sales_and_managers` have been pre-computed exactly as you did in the previous exercise.\n",
    "\n",
    "The merged DataFrames contain enough information to construct a DataFrame with 5 rows with all known information correctly aligned and each branch listed only once. You will try to merge the merged DataFrames on all matching keys (which computes an inner join by default). You can compare the result to an outer join and also to an outer join with restricted subset of columns as keys.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Merge `sales_and_managers` with `revenue_and_sales`. Store the result as `merge_default`.\n",
    "- Print `merge_default`. This has been done for you.\n",
    "- Merge `sales_and_managers` with `revenue_and_sales` using `how='outer'`. Store the result as `merge_outer`.\n",
    "- Print `merge_outer`. This has been done for you.\n",
    "- Merge `sales_and_managers` with `revenue_and_sales` only on `['city','state']` using an outer join. Store the result as `merge_outer_on` and hit 'Submit Answer' to see what the merged DataFrames look like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        city state  units  branch_id     branch   manager  revenue\n",
      "0  Mendocino    CA      1       47.0  Mendocino     Brett    200.0\n",
      "1     Denver    CO      4       20.0     Denver      Joel     83.0\n",
      "2     Austin    TX      2       10.0     Austin  Charlers    100.0\n",
      "\n",
      "\n",
      "          city state  units  branch_id       branch   manager  revenue\n",
      "0    Mendocino    CA      1       47.0    Mendocino     Brett    200.0\n",
      "1       Denver    CO      4       20.0       Denver      Joel     83.0\n",
      "2       Austin    TX      2       10.0       Austin  Charlers    100.0\n",
      "3  Springfield    MO      5       31.0  Springfield     Sally      NaN\n",
      "4  Springfield    IL      1        NaN          NaN       NaN      NaN\n",
      "5  Springfield    IL      1       30.0          NaN       NaN      4.0\n",
      "6  Springfield    MO      5        NaN          NaN       NaN      NaN\n",
      "\n",
      "\n",
      "          city state  units_x  branch_id_x       branch   manager  \\\n",
      "0    Mendocino    CA        1         47.0    Mendocino     Brett   \n",
      "1       Denver    CO        4         20.0       Denver      Joel   \n",
      "2       Austin    TX        2         10.0       Austin  Charlers   \n",
      "3  Springfield    MO        5         31.0  Springfield     Sally   \n",
      "4  Springfield    IL        1          NaN          NaN       NaN   \n",
      "\n",
      "   branch_id_y  revenue  units_y  \n",
      "0         47.0    200.0        1  \n",
      "1         20.0     83.0        4  \n",
      "2         10.0    100.0        2  \n",
      "3          NaN      NaN        5  \n",
      "4         30.0      4.0        1  \n"
     ]
    }
   ],
   "source": [
    "# Perform the first merge: merge_default\n",
    "merge_default = pd.merge(sales_and_managers, revenue_and_sales)\n",
    "\n",
    "# Print merge_default\n",
    "print(merge_default)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Perform the second merge: merge_outer\n",
    "merge_outer = pd.merge(sales_and_managers, revenue_and_sales, how='outer')\n",
    "\n",
    "# Print merge_outer\n",
    "print(merge_outer)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Perform the third merge: merge_outer_on\n",
    "merge_outer_on = pd.merge(sales_and_managers, revenue_and_sales, how='outer', on=['city', 'state'])\n",
    "\n",
    "# Print merge_outer_on\n",
    "print(merge_outer_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using merge_ordered()\n",
    "\n",
    "This exercise uses pre-loaded DataFrames `austin` and `houston` that contain weather data from the cities Austin and Houston respectively. They have been printed in the IPython Shell for you to examine.\n",
    "\n",
    "Weather conditions were recorded on separate days and you need to merge these two DataFrames together such that the dates are ordered. To do this, you'll use `pd.merge_ordered()`. After you're done, note the order of the rows before and after merging.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Perform an ordered merge on `austin` and `houston` using `pd.merge_ordered()`. Store the result as `tx_weather`.\n",
    "- Print `tx_weather`. You should notice that the rows are sorted by the date but it is not possible to tell which observation came from which city.\n",
    "- Perform another ordered merge on `austin` and `houston`.\n",
    "    - This time, specify the keyword arguments `on='date'` and `suffixes=['_aus','_hus']` so that the rows can be distinguished. Store the result as `tx_weather_suff`.\n",
    "- Print `tx_weather_suff` to examine its contents. This has been done for you.\n",
    "- Perform a third ordered merge on `austin` and `houston`.\n",
    "    - This time, in addition to the `on` and `suffixes` parameters, specify the keyword argument `fill_method='ffill'` to use *forward-filling* to replace `NaN` entries with the most recent non-null entry, and hit 'Submit Answer' to examine the contents of the merged DataFrames!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date ratings\n",
      "0 2016-01-01  Cloudy\n",
      "1 2016-01-04   Rainy\n",
      "2 2016-01-17   Sunny\n",
      "3 2016-02-08  Cloudy\n",
      "4 2016-03-01   Sunny\n",
      "\n",
      "\n",
      "        date ratings_aus ratings_hus\n",
      "0 2016-01-01      Cloudy      Cloudy\n",
      "1 2016-01-04         NaN       Rainy\n",
      "2 2016-01-17       Sunny         NaN\n",
      "3 2016-02-08      Cloudy         NaN\n",
      "4 2016-03-01         NaN       Sunny\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ratings_aus</th>\n",
       "      <th>ratings_hus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-08</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date ratings_aus ratings_hus\n",
       "0 2016-01-01      Cloudy      Cloudy\n",
       "1 2016-01-04      Cloudy       Rainy\n",
       "2 2016-01-17       Sunny       Rainy\n",
       "3 2016-02-08      Cloudy       Rainy\n",
       "4 2016-03-01      Cloudy       Sunny"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import Timestamp\n",
    "austin = pd.DataFrame({'date': {0: Timestamp('2016-01-01 00:00:00'),\n",
    "  1: Timestamp('2016-02-08 00:00:00'),\n",
    "  2: Timestamp('2016-01-17 00:00:00')},\n",
    " 'ratings': {0: 'Cloudy', 1: 'Cloudy', 2: 'Sunny'}})\n",
    "\n",
    "houston = pd.DataFrame({'date': {0: Timestamp('2016-01-04 00:00:00'),\n",
    "  1: Timestamp('2016-01-01 00:00:00'),\n",
    "  2: Timestamp('2016-03-01 00:00:00')},\n",
    " 'ratings': {0: 'Rainy', 1: 'Cloudy', 2: 'Sunny'}})\n",
    "\n",
    "# Perform the first ordered merge: tx_weather\n",
    "tx_weather = pd.merge_ordered(austin, houston)\n",
    "\n",
    "# Print tx_weather\n",
    "print(tx_weather)\n",
    "\n",
    "# Perform the second ordered merge: tx_weather_suff\n",
    "tx_weather_suff = pd.merge_ordered(austin, houston, on='date', suffixes=['_aus', '_hus'])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Print tx_weather_suff\n",
    "print(tx_weather_suff)\n",
    "\n",
    "# Perform the third ordered merge: tx_weather_ffill\n",
    "tx_weather_ffill = pd.merge_ordered(austin, houston, on='date', suffixes=['_aus', '_hus'], fill_method='ffill')\n",
    "\n",
    "# Print tx_weather_ffill\n",
    "tx_weather_ffill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using merge_asof()\n",
    "\n",
    "Similar to `pd.merge_ordered()`, the `pd.merge_asof()` function will also merge values in order using the `on` column, but for each row in the left DataFrame, only rows from the right DataFrame whose `'on'` column values are **less** than the left value will be kept.\n",
    "\n",
    "This function can be used to align disparate datetime frequencies without having to first resample.\n",
    "\n",
    "Here, you'll merge monthly oil prices (US dollars) into a full automobile fuel efficiency dataset. The oil and automobile DataFrames have been pre-loaded as `oil` and `auto`. The first 5 rows of each have been printed in the IPython Shell for you to explore.\n",
    "\n",
    "These datasets will align such that the first price of the year will be broadcast into the rows of the automobiles DataFrame. This is considered correct since by the start of any given year, most automobiles for that year will have already been manufactured.\n",
    "\n",
    "You'll then inspect the merged DataFrame, resample by year and compute the mean `'Price'` and `'mpg'`. You should be able to see a trend in these two columns, that you can confirm by computing the Pearson correlation between resampled `'Price'` and `'mpg'`.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Merge `auto` and `oil` using `pd.merge_asof()` with `left_on='yr'` and `right_on='Date'`. Store the result as `merged`.\n",
    "- Print the tail of `merged`. This has been done for you.\n",
    "- Resample `merged` using `'A'` (annual frequency), and `on='Date'`. Select `[['mpg','Price']]` and aggregate the mean. Store the result as `yearly`.\n",
    "- Hit Submit Answer to examine the contents of `yearly` and `yearly.corr()`, which shows the Pearson correlation between the resampled `'Price'` and `'mpg'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970-02-01</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-03-01</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Price\n",
       "0 1970-01-01   3.35\n",
       "1 1970-02-01   3.35\n",
       "2 1970-03-01   3.35"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the dataset\n",
    "oil = pd.read_csv('data/oil_price.csv', parse_dates=['Date'])\n",
    "oil.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>yr</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cyl  displ   hp  weight  accel         yr origin  \\\n",
       "0  18.0    8  307.0  130    3504   12.0 1970-01-01     US   \n",
       "1  15.0    8  350.0  165    3693   11.5 1970-01-01     US   \n",
       "2  18.0    8  318.0  150    3436   11.0 1970-01-01     US   \n",
       "\n",
       "                        name  \n",
       "0  chevrolet chevelle malibu  \n",
       "1          buick skylark 320  \n",
       "2         plymouth satellite  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.read_csv('data/automobiles.csv', parse_dates=['yr'])\n",
    "auto.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      mpg  cyl  displ  hp  weight  accel         yr  origin             name  \\\n",
      "387  27.0    4  140.0  86    2790   15.6 1982-01-01      US  ford mustang gl   \n",
      "388  44.0    4   97.0  52    2130   24.6 1982-01-01  Europe        vw pickup   \n",
      "389  32.0    4  135.0  84    2295   11.6 1982-01-01      US    dodge rampage   \n",
      "390  28.0    4  120.0  79    2625   18.6 1982-01-01      US      ford ranger   \n",
      "391  31.0    4  119.0  82    2720   19.4 1982-01-01      US       chevy s-10   \n",
      "\n",
      "          Date  Price  \n",
      "387 1982-01-01  33.85  \n",
      "388 1982-01-01  33.85  \n",
      "389 1982-01-01  33.85  \n",
      "390 1982-01-01  33.85  \n",
      "391 1982-01-01  33.85  \n",
      "                  mpg  Price\n",
      "Date                        \n",
      "1970-12-31  17.689655   3.35\n",
      "1971-12-31  21.111111   3.56\n",
      "1972-12-31  18.714286   3.56\n",
      "1973-12-31  17.100000   3.56\n",
      "1974-12-31  22.769231  10.11\n",
      "1975-12-31  20.266667  11.16\n",
      "1976-12-31  21.573529  11.16\n",
      "1977-12-31  23.375000  13.90\n",
      "1978-12-31  24.061111  14.85\n",
      "1979-12-31  25.093103  14.85\n",
      "1980-12-31  33.803704  32.50\n",
      "1981-12-31  30.185714  38.00\n",
      "1982-12-31  32.000000  33.85\n",
      "            mpg     Price\n",
      "mpg    1.000000  0.948677\n",
      "Price  0.948677  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Merge auto and oil: merged\n",
    "merged = pd.merge_asof(auto, oil, left_on='yr', right_on='Date')\n",
    "\n",
    "# Print the tail of merged\n",
    "print(merged.tail())\n",
    "\n",
    "# Resample merged: yearly\n",
    "yearly = merged.resample('A', on='Date')[['mpg', 'Price']].mean()\n",
    "\n",
    "# Print yearly\n",
    "print(yearly)\n",
    "\n",
    "# print yearly.corr()\n",
    "print(yearly.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Case Study - Summer Olympics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Olympic edition DataFrame\n",
    "\n",
    "In this chapter, you'll be using [The Guardian's Olympic medal dataset](https://www.theguardian.com/sport/datablog/2012/jun/25/olympic-medal-winner-list-data).\n",
    "\n",
    "Your first task here is to prepare a DataFrame `editions` from a *tab-separated values* (TSV) file.\n",
    "\n",
    "Initially, `editions` has 26 rows (one for each Olympic edition, i.e., a year in which the Olympics was held) and 7 columns: `'Edition'`, `'Bronze'`, `'Gold'`, `'Silver'`, `'Grand Total'`, `'City'`, and `'Country'`.\n",
    "\n",
    "For the analysis that follows, you won't need the overall medal counts, so you want to keep only the useful columns from `editions`: `'Edition'`, `'Grand Total'`, `City`, and `Country`.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Read `file_path` into a DataFrame called `editions`. The identifier `file_path` has been pre-defined with the filename `'Summer Olympic medallists 1896 to 2008 - EDITIONS.tsv'`. You'll have to use the option `sep='\\t'` because the file uses tabs to delimit fields (`pd.read_csv()` expects commas by default).\n",
    "- Select only the columns `'Edition'`, `'Grand Total'`, `'City'`, and `'Country'` from editions.\n",
    "- Print the final DataFrame `editions` in entirety (there are only 26 rows). This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Edition</th>\n",
       "      <th>Grand Total</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1896</td>\n",
       "      <td>151</td>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900</td>\n",
       "      <td>512</td>\n",
       "      <td>Paris</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1904</td>\n",
       "      <td>470</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1908</td>\n",
       "      <td>804</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1912</td>\n",
       "      <td>885</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1920</td>\n",
       "      <td>1298</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1924</td>\n",
       "      <td>884</td>\n",
       "      <td>Paris</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1928</td>\n",
       "      <td>710</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1932</td>\n",
       "      <td>615</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1936</td>\n",
       "      <td>875</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1948</td>\n",
       "      <td>814</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1952</td>\n",
       "      <td>889</td>\n",
       "      <td>Helsinki</td>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1956</td>\n",
       "      <td>885</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1960</td>\n",
       "      <td>882</td>\n",
       "      <td>Rome</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1964</td>\n",
       "      <td>1010</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1968</td>\n",
       "      <td>1031</td>\n",
       "      <td>Mexico City</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1972</td>\n",
       "      <td>1185</td>\n",
       "      <td>Munich</td>\n",
       "      <td>West Germany (now Germany)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1976</td>\n",
       "      <td>1305</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1980</td>\n",
       "      <td>1387</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>U.S.S.R. (now Russia)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1984</td>\n",
       "      <td>1459</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1988</td>\n",
       "      <td>1546</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>South Korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1992</td>\n",
       "      <td>1705</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1996</td>\n",
       "      <td>1859</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2000</td>\n",
       "      <td>2015</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2004</td>\n",
       "      <td>1998</td>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2008</td>\n",
       "      <td>2042</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Edition  Grand Total         City                     Country\n",
       "0      1896          151       Athens                      Greece\n",
       "1      1900          512        Paris                      France\n",
       "2      1904          470    St. Louis               United States\n",
       "3      1908          804       London              United Kingdom\n",
       "4      1912          885    Stockholm                      Sweden\n",
       "5      1920         1298      Antwerp                     Belgium\n",
       "6      1924          884        Paris                      France\n",
       "7      1928          710    Amsterdam                 Netherlands\n",
       "8      1932          615  Los Angeles               United States\n",
       "9      1936          875       Berlin                     Germany\n",
       "10     1948          814       London              United Kingdom\n",
       "11     1952          889     Helsinki                     Finland\n",
       "12     1956          885    Melbourne                   Australia\n",
       "13     1960          882         Rome                       Italy\n",
       "14     1964         1010        Tokyo                       Japan\n",
       "15     1968         1031  Mexico City                      Mexico\n",
       "16     1972         1185       Munich  West Germany (now Germany)\n",
       "17     1976         1305     Montreal                      Canada\n",
       "18     1980         1387       Moscow       U.S.S.R. (now Russia)\n",
       "19     1984         1459  Los Angeles               United States\n",
       "20     1988         1546        Seoul                 South Korea\n",
       "21     1992         1705    Barcelona                       Spain\n",
       "22     1996         1859      Atlanta               United States\n",
       "23     2000         2015       Sydney                   Australia\n",
       "24     2004         1998       Athens                      Greece\n",
       "25     2008         2042      Beijing                       China"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# Create file path: file_path\n",
    "file_path = 'data/Summer Olympic medalists 1896 to 2008 - EDITIONS.tsv'\n",
    "\n",
    "# Load DataFrame from file_path: editions\n",
    "editions = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# Extract the relevant columns: editions\n",
    "editions = editions[['Edition', 'Grand Total', 'City', 'Country']]\n",
    "\n",
    "# Print editions DataFrame\n",
    "editions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading IOC codes DataFrame\n",
    "\n",
    "Your task here is to prepare a DataFrame `ioc_codes` from a comma-separated values (CSV) file.\n",
    "\n",
    "Initially, `ioc_codes` has 200 rows (one for each country) and 3 columns: `'Country'`, `'NOC'`, & `'ISO code'`.\n",
    "\n",
    "For the analysis that follows, you want to keep only the useful columns from `ioc_codes`: `'Country'` and `'NOC'` (the column `'NOC'` contains three-letter codes representing each country).\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Read `file_path` into a DataFrame called `ioc_codes`. The identifier `file_path` has been pre-defined with the filename `'Summer Olympic medallists 1896 to 2008 - IOC COUNTRY CODES.csv'`.\n",
    "- Select only the columns `'Country'` and `'NOC'` from `ioc_codes`.\n",
    "- Print the leading 5 and trailing 5 rows of the DataFrame `ioc_codes` (there are 200 rows in total). This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Country  NOC\n",
      "0      Afghanistan  AFG\n",
      "1          Albania  ALB\n",
      "2          Algeria  ALG\n",
      "3  American Samoa*  ASA\n",
      "4          Andorra  AND\n",
      "\n",
      "\n",
      "             Country  NOC\n",
      "196          Vietnam  VIE\n",
      "197  Virgin Islands*  ISV\n",
      "198            Yemen  YEM\n",
      "199           Zambia  ZAM\n",
      "200         Zimbabwe  ZIM\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# Create the file path: file_path\n",
    "file_path = 'data/Summer Olympic medalists 1896 to 2008 - IOC COUNTRY CODES.csv'\n",
    "\n",
    "# Load DataFrame from file_path: ioc_codes\n",
    "ioc_codes = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the relevant columns: ioc_codes\n",
    "ioc_codes = ioc_codes[['Country', 'NOC']]\n",
    "\n",
    "# Print first and last 5 rows of ioc_codes\n",
    "print(ioc_codes.head())\n",
    "print('\\n')\n",
    "print(ioc_codes.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building medals DataFrame\n",
    "\n",
    "Here, you'll start with the DataFrame `editions` from the previous exercise.\n",
    "\n",
    "You have a sequence of files `summer_1896.csv`, `summer_1900.csv`, ..., `summer_2008.csv`, one for each Olympic edition (year).\n",
    "\n",
    "You will build up a dictionary `medals_dict` with the Olympic editions (years) as keys and DataFrames as values.\n",
    "\n",
    "The dictionary is built up inside a loop over the `year` of each Olympic edition (from the Index of editions).\n",
    "\n",
    "Once the dictionary of DataFrames is built up, you will combine the DataFrames using `pd.concat()`.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Within the `for` loop:\n",
    "    - Create the file path. This has been done for you.\n",
    "    - Read `file_path` into a DataFrame. Assign the result to the `year` key of `medals_dict`.\n",
    "    - Select only the columns `'Athlete'`, `'NOC'`, and `'Medal'` from `medals_dict[year]`.\n",
    "    - Create a new column called `'Edition'` in the DataFrame `medals_dict[year]` whose entries are all `year`.\n",
    "- Concatenate the dictionary of DataFrames `medals_dict` into a DataFame called `medals`. Specify the keyword argument `ignore_index=True` to prevent repeated integer indices.\n",
    "- Print the first and last 5 rows of `medals`. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# # Create empty dictionary: medals_dict\n",
    "# medals_dict = {}\n",
    "\n",
    "# for year in editions['Edition']:\n",
    "\n",
    "#     # Create the file path: file_path\n",
    "#     file_path = 'summer_{:d}.csv'.format(year)\n",
    "    \n",
    "#     # Load file_path into a DataFrame: medals_dict[year]\n",
    "#     medals_dict[year] = pd.read_csv(file_path)\n",
    "    \n",
    "#     # Extract relevant columns: medals_dict[year]\n",
    "#     medals_dict[year] = medals_dict[year][['Athlete', 'NOC', 'Medal']]\n",
    "    \n",
    "#     # Assign year to column 'Edition' of medals_dict\n",
    "#     medals_dict[year]['Edition'] = year\n",
    "    \n",
    "# # Concatenate medals_dict: medals\n",
    "# medals = pd.concat(medals_dict, ignore_index=True)\n",
    "\n",
    "# # Print first and last 5 rows of medals\n",
    "# print(medals.head())\n",
    "# print(medals.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are too many `.csv` files in this question, therefore passing without execution. Final `medals` dataframe has been created in the following cell. For `file_path = 'summer_{:d}.csv'.format(year)`  [click here](https://stackoverflow.com/questions/34252018/what-does-d-mean-strings-python-3-4-3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Athlete</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Medal</th>\n",
       "      <th>Edition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAJOS, Alfred</td>\n",
       "      <td>HUN</td>\n",
       "      <td>Gold</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HERSCHMANN, Otto</td>\n",
       "      <td>AUT</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Athlete  NOC   Medal  Edition\n",
       "0     HAJOS, Alfred  HUN    Gold     1896\n",
       "1  HERSCHMANN, Otto  AUT  Silver     1896"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medals = pd.read_csv('data/Summer Olympic medalists 1896 to 2008 - ALL MEDALISTS.tsv', sep='\\t', skiprows=4)\n",
    "medals = medals[['Athlete', 'NOC', 'Medal', 'Edition']]\n",
    "medals.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting medals by country/edition in a pivot table\n",
    "\n",
    "Here, you'll start with the concatenated DataFrame `medals` from the previous exercise.\n",
    "\n",
    "You can construct a *pivot table* to see the number of medals each country won in each year. The result is a new DataFrame with the Olympic edition on the Index and with 138 country `NOC` codes as columns. If you want a refresher on pivot tables, it may be useful to refer back to the relevant exercises in [Manipulating DataFrames with pandas](https://campus.datacamp.com/courses/manipulating-dataframes-with-pandas/rearranging-and-reshaping-data?ex=14).\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Construct a pivot table from the DataFrame `medals`, aggregating by `count` (by specifying the `aggfunc` parameter). Use `'Edition'` as the `index`, `'Athlete'` for the `values`, and `'NOC'` for the columns.\n",
    "- Print the first & last 5 rows of `medal_counts`. This has been done for you, so hit 'Submit Answer' to see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOC      AFG  AHO  ALG   ANZ  ARG  ARM  AUS   AUT  AZE  BAH  ...  URS  URU  \\\n",
      "Edition                                                      ...             \n",
      "1896     NaN  NaN  NaN   NaN  NaN  NaN  2.0   5.0  NaN  NaN  ...  NaN  NaN   \n",
      "1900     NaN  NaN  NaN   NaN  NaN  NaN  5.0   6.0  NaN  NaN  ...  NaN  NaN   \n",
      "1904     NaN  NaN  NaN   NaN  NaN  NaN  NaN   1.0  NaN  NaN  ...  NaN  NaN   \n",
      "1908     NaN  NaN  NaN  19.0  NaN  NaN  NaN   1.0  NaN  NaN  ...  NaN  NaN   \n",
      "1912     NaN  NaN  NaN  10.0  NaN  NaN  NaN  14.0  NaN  NaN  ...  NaN  NaN   \n",
      "\n",
      "NOC        USA  UZB  VEN  VIE  YUG  ZAM  ZIM   ZZX  \n",
      "Edition                                             \n",
      "1896      20.0  NaN  NaN  NaN  NaN  NaN  NaN   6.0  \n",
      "1900      55.0  NaN  NaN  NaN  NaN  NaN  NaN  34.0  \n",
      "1904     394.0  NaN  NaN  NaN  NaN  NaN  NaN   8.0  \n",
      "1908      63.0  NaN  NaN  NaN  NaN  NaN  NaN   NaN  \n",
      "1912     101.0  NaN  NaN  NaN  NaN  NaN  NaN   NaN  \n",
      "\n",
      "[5 rows x 138 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>NOC</th>\n",
       "      <th>AFG</th>\n",
       "      <th>AHO</th>\n",
       "      <th>ALG</th>\n",
       "      <th>ANZ</th>\n",
       "      <th>ARG</th>\n",
       "      <th>ARM</th>\n",
       "      <th>AUS</th>\n",
       "      <th>AUT</th>\n",
       "      <th>AZE</th>\n",
       "      <th>BAH</th>\n",
       "      <th>...</th>\n",
       "      <th>URS</th>\n",
       "      <th>URU</th>\n",
       "      <th>USA</th>\n",
       "      <th>UZB</th>\n",
       "      <th>VEN</th>\n",
       "      <th>VIE</th>\n",
       "      <th>YUG</th>\n",
       "      <th>ZAM</th>\n",
       "      <th>ZIM</th>\n",
       "      <th>ZZX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edition</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>264.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "NOC      AFG  AHO  ALG  ANZ   ARG  ARM    AUS  AUT  AZE  BAH  ...  URS  URU  \\\n",
       "Edition                                                       ...             \n",
       "1992     NaN  NaN  2.0  NaN   2.0  NaN   57.0  6.0  NaN  1.0  ...  NaN  NaN   \n",
       "1996     NaN  NaN  3.0  NaN  20.0  2.0  132.0  3.0  1.0  5.0  ...  NaN  NaN   \n",
       "2000     NaN  NaN  5.0  NaN  20.0  1.0  183.0  4.0  3.0  6.0  ...  NaN  1.0   \n",
       "2004     NaN  NaN  NaN  NaN  47.0  NaN  157.0  8.0  5.0  2.0  ...  NaN  NaN   \n",
       "2008     1.0  NaN  2.0  NaN  51.0  6.0  149.0  3.0  7.0  5.0  ...  NaN  NaN   \n",
       "\n",
       "NOC        USA  UZB  VEN  VIE   YUG  ZAM  ZIM  ZZX  \n",
       "Edition                                             \n",
       "1992     224.0  NaN  NaN  NaN   NaN  NaN  NaN  NaN  \n",
       "1996     260.0  2.0  NaN  NaN  26.0  1.0  NaN  NaN  \n",
       "2000     248.0  4.0  NaN  1.0  26.0  NaN  NaN  NaN  \n",
       "2004     264.0  5.0  2.0  NaN   NaN  NaN  3.0  NaN  \n",
       "2008     315.0  6.0  1.0  1.0   NaN  NaN  4.0  NaN  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the pivot_table: medal_counts\n",
    "medal_counts = medals.pivot_table(index = 'Edition', columns = 'NOC', values = 'Athlete', aggfunc = 'count')\n",
    "\n",
    "# Print the first & last 5 rows of medal_counts\n",
    "print(medal_counts.head())\n",
    "medal_counts.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing fraction of medals per Olympic edition\n",
    "\n",
    "In this exercise, you'll start with the DataFrames `editions`, `medals`, & `medal_counts` from prior exercises.\n",
    "\n",
    "You can extract a Series with the total number of medals awarded in each Olympic edition.\n",
    "\n",
    "The DataFrame `medal_counts` can be divided row-wise by the total number of medals awarded each edition; the method `.divide()` performs the broadcast as you require.\n",
    "\n",
    "This gives you a normalized indication of each country's performance in each edition.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Set the index of the DataFrame `editions` to be `'Edition'` (using the method `.set_index()`). Save the result as `totals`.\n",
    "- Extract the `'Grand Total'` column from `totals` and assign the result back to `totals`.\n",
    "- Divide the DataFrame `medal_counts` by `totals` along each row. You will have to use the `.divide()` method with the option `axis='rows'`. Assign the result to `fractions`.\n",
    "- Print first & last 5 rows of the DataFrame `fractions`. This has been done for you, so hit 'Submit Answer' to see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOC      AFG  AHO  ALG       ANZ  ARG  ARM       AUS       AUT  AZE  BAH  ...  \\\n",
      "Edition                                                                   ...   \n",
      "1896     NaN  NaN  NaN       NaN  NaN  NaN  0.013245  0.033113  NaN  NaN  ...   \n",
      "1900     NaN  NaN  NaN       NaN  NaN  NaN  0.009766  0.011719  NaN  NaN  ...   \n",
      "1904     NaN  NaN  NaN       NaN  NaN  NaN       NaN  0.002128  NaN  NaN  ...   \n",
      "1908     NaN  NaN  NaN  0.023632  NaN  NaN       NaN  0.001244  NaN  NaN  ...   \n",
      "1912     NaN  NaN  NaN  0.011299  NaN  NaN       NaN  0.015819  NaN  NaN  ...   \n",
      "\n",
      "NOC      URS  URU       USA  UZB  VEN  VIE  YUG  ZAM  ZIM       ZZX  \n",
      "Edition                                                              \n",
      "1896     NaN  NaN  0.132450  NaN  NaN  NaN  NaN  NaN  NaN  0.039735  \n",
      "1900     NaN  NaN  0.107422  NaN  NaN  NaN  NaN  NaN  NaN  0.066406  \n",
      "1904     NaN  NaN  0.838298  NaN  NaN  NaN  NaN  NaN  NaN  0.017021  \n",
      "1908     NaN  NaN  0.078358  NaN  NaN  NaN  NaN  NaN  NaN       NaN  \n",
      "1912     NaN  NaN  0.114124  NaN  NaN  NaN  NaN  NaN  NaN       NaN  \n",
      "\n",
      "[5 rows x 138 columns]\n",
      "NOC          AFG  AHO       ALG  ANZ       ARG       ARM       AUS       AUT  \\\n",
      "Edition                                                                        \n",
      "1992         NaN  NaN  0.001173  NaN  0.001173       NaN  0.033431  0.003519   \n",
      "1996         NaN  NaN  0.001614  NaN  0.010758  0.001076  0.071006  0.001614   \n",
      "2000         NaN  NaN  0.002481  NaN  0.009926  0.000496  0.090819  0.001985   \n",
      "2004         NaN  NaN       NaN  NaN  0.023524       NaN  0.078579  0.004004   \n",
      "2008     0.00049  NaN  0.000979  NaN  0.024976  0.002938  0.072968  0.001469   \n",
      "\n",
      "NOC           AZE       BAH  ...  URS       URU       USA       UZB       VEN  \\\n",
      "Edition                      ...                                                \n",
      "1992          NaN  0.000587  ...  NaN       NaN  0.131378       NaN       NaN   \n",
      "1996     0.000538  0.002690  ...  NaN       NaN  0.139860  0.001076       NaN   \n",
      "2000     0.001489  0.002978  ...  NaN  0.000496  0.123077  0.001985       NaN   \n",
      "2004     0.002503  0.001001  ...  NaN       NaN  0.132132  0.002503  0.001001   \n",
      "2008     0.003428  0.002449  ...  NaN       NaN  0.154261  0.002938  0.000490   \n",
      "\n",
      "NOC           VIE       YUG       ZAM       ZIM  ZZX  \n",
      "Edition                                               \n",
      "1992          NaN       NaN       NaN       NaN  NaN  \n",
      "1996          NaN  0.013986  0.000538       NaN  NaN  \n",
      "2000     0.000496  0.012903       NaN       NaN  NaN  \n",
      "2004          NaN       NaN       NaN  0.001502  NaN  \n",
      "2008     0.000490       NaN       NaN  0.001959  NaN  \n",
      "\n",
      "[5 rows x 138 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set Index of editions: totals\n",
    "totals = editions.set_index('Edition')\n",
    "\n",
    "# Reassign totals['Grand Total']: totals\n",
    "totals = totals['Grand Total']\n",
    "\n",
    "# Divide medal_counts by totals: fractions\n",
    "fractions = medal_counts.divide(totals, axis='rows')\n",
    "\n",
    "# Print first & last 5 rows of fractions\n",
    "print(fractions.head())\n",
    "print(fractions.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataframe values are normalized. It makes sense. In the 1896 `Edition` there were **151** total medals, therefore let's say 60 medals won by a country is a significant indicator. On contrary, in the 2008 `Edition` of Olympics, there were **2042** total medals, therefore 60 medals won by a country is not that significant as it was the case before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing percentage change in fraction of medals won\n",
    "\n",
    "Here, you'll start with the DataFrames `editions`, `medals`, `medal_counts`, & `fractions` from prior exercises.\n",
    "\n",
    "To see if there is a host country advantage, you first want to see how the fraction of medals won changes from edition to edition.\n",
    "\n",
    "The *expanding mean* provides a way to see this down each column. It is the value of the mean with all the data available up to that point in time. If you are interested in learning more about pandas' expanding transformations, this section of the [pandas documentation](http://pandas.pydata.org/pandas-docs/stable/computation.html#expanding-windows) has additional information.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Create `mean_fractions` by chaining the methods `.expanding().mean()` to `fractions`.\n",
    "- Compute the percentage change in `mean_fractions` down each column by applying `.pct_change()` and multiplying by `100`. Assign the result to `fractions_change`.\n",
    "- Reset the index of `fractions_change` using the `.reset_index()` method. This will make `'Edition'` an ordinary column.\n",
    "- Print the first and last 5 rows of the DataFrame `fractions_change`. This has been done for you, so hit 'Submit Answer' to see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>NOC</th>\n",
       "      <th>Edition</th>\n",
       "      <th>AFG</th>\n",
       "      <th>AHO</th>\n",
       "      <th>ALG</th>\n",
       "      <th>ANZ</th>\n",
       "      <th>ARG</th>\n",
       "      <th>ARM</th>\n",
       "      <th>AUS</th>\n",
       "      <th>AUT</th>\n",
       "      <th>AZE</th>\n",
       "      <th>...</th>\n",
       "      <th>URS</th>\n",
       "      <th>URU</th>\n",
       "      <th>USA</th>\n",
       "      <th>UZB</th>\n",
       "      <th>VEN</th>\n",
       "      <th>VIE</th>\n",
       "      <th>YUG</th>\n",
       "      <th>ZAM</th>\n",
       "      <th>ZIM</th>\n",
       "      <th>ZZX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.134766</td>\n",
       "      <td>-32.304688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.448242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.561198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-30.169386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199.651245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.642384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23.013510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19.549222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-26.092774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.254438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.105733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "NOC  Edition  AFG  AHO  ALG        ANZ  ARG  ARM        AUS        AUT  AZE  \\\n",
       "0       1896  NaN  NaN  NaN        NaN  NaN  NaN        NaN        NaN  NaN   \n",
       "1       1900  NaN  NaN  NaN        NaN  NaN  NaN -13.134766 -32.304688  NaN   \n",
       "2       1904  NaN  NaN  NaN        NaN  NaN  NaN   0.000000 -30.169386  NaN   \n",
       "3       1908  NaN  NaN  NaN        NaN  NaN  NaN   0.000000 -23.013510  NaN   \n",
       "4       1912  NaN  NaN  NaN -26.092774  NaN  NaN   0.000000   6.254438  NaN   \n",
       "\n",
       "NOC  ...  URS  URU         USA  UZB  VEN  VIE  YUG  ZAM  ZIM        ZZX  \n",
       "0    ...  NaN  NaN         NaN  NaN  NaN  NaN  NaN  NaN  NaN        NaN  \n",
       "1    ...  NaN  NaN   -9.448242  NaN  NaN  NaN  NaN  NaN  NaN  33.561198  \n",
       "2    ...  NaN  NaN  199.651245  NaN  NaN  NaN  NaN  NaN  NaN -22.642384  \n",
       "3    ...  NaN  NaN  -19.549222  NaN  NaN  NaN  NaN  NaN  NaN   0.000000  \n",
       "4    ...  NaN  NaN  -12.105733  NaN  NaN  NaN  NaN  NaN  NaN   0.000000  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the expanding mean: mean_fractions\n",
    "mean_fractions = fractions.expanding().mean()\n",
    "\n",
    "# Compute the percentage change: fractions_change\n",
    "fractions_change = mean_fractions.pct_change()*100\n",
    "\n",
    "# Reset the index of fractions_change: fractions_change\n",
    "fractions_change = fractions_change.reset_index()\n",
    "\n",
    "# Print first & last 5 rows of fractions_change\n",
    "fractions_change.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building hosts DataFrame\n",
    "\n",
    "Your task here is to prepare a DataFrame `hosts` by left joining `editions` and `ioc_codes`.\n",
    "\n",
    "Once created, you will subset the `Edition` and `NOC` columns and set `Edition` as the Index.\n",
    "\n",
    "There are some missing `NOC` values; you will set those explicitly.\n",
    "\n",
    "Finally, you'll reset the Index & print the final DataFrame.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Create the DataFrame `hosts` by doing a *left join* on DataFrames `editions` and `ioc_codes` (using `pd.merge()`).\n",
    "- Clean up `hosts` by subsetting and setting the Index.\n",
    "    - Extract the columns `'Edition'` and `'NOC'`.\n",
    "    - Set `'Edition'` column as the Index.\n",
    "- Use the `.loc[]` accessor to find and assign the missing values to the `'NOC'` column in `hosts`. This has been done for you.\n",
    "- Reset the index of `hosts` using `.reset_index()`, which you'll need to save as the `hosts` DataFrame.\n",
    "- Hit 'Submit Answer' to see what `hosts` looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         NOC\n",
      "Edition     \n",
      "1972     NaN\n",
      "1980     NaN\n",
      "1988     NaN\n",
      "\n",
      "\n",
      "    Edition  NOC\n",
      "0      1896  GRE\n",
      "1      1900  FRA\n",
      "2      1904  USA\n",
      "3      1908  GBR\n",
      "4      1912  SWE\n",
      "5      1920  BEL\n",
      "6      1924  FRA\n",
      "7      1928  NED\n",
      "8      1932  USA\n",
      "9      1936  GER\n",
      "10     1948  GBR\n",
      "11     1952  FIN\n",
      "12     1956  AUS\n",
      "13     1960  ITA\n",
      "14     1964  JPN\n",
      "15     1968  MEX\n",
      "16     1972  FRG\n",
      "17     1976  CAN\n",
      "18     1980  URS\n",
      "19     1984  USA\n",
      "20     1988  KOR\n",
      "21     1992  ESP\n",
      "22     1996  USA\n",
      "23     2000  AUS\n",
      "24     2004  GRE\n",
      "25     2008  CHN\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# Left join editions and ioc_codes: hosts\n",
    "hosts = pd.merge(editions, ioc_codes, how='left')\n",
    "\n",
    "# Extract relevant columns and set index: hosts\n",
    "hosts = hosts[['Edition', 'NOC']].set_index('Edition')\n",
    "\n",
    "# Fix missing 'NOC' values of hosts\n",
    "print(hosts.loc[hosts.NOC.isnull()])\n",
    "hosts.loc[1972, 'NOC'] = 'FRG'\n",
    "hosts.loc[1980, 'NOC'] = 'URS'\n",
    "hosts.loc[1988, 'NOC'] = 'KOR'\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Reset Index of hosts: hosts\n",
    "hosts = hosts.reset_index()\n",
    "\n",
    "# Print hosts\n",
    "print(hosts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping for analysis\n",
    "\n",
    "This exercise starts off with `fractions_change` and `hosts` already loaded.\n",
    "\n",
    "Your task here is to reshape the `fractions_change` DataFrame for later analysis.\n",
    "\n",
    "Initially, `fractions_change` is a wide DataFrame of 26 rows (one for each Olympic edition) and 139 columns (one for the edition and 138 for the competing countries).\n",
    "\n",
    "On reshaping with `pd.melt()`, as you will see, the result is a tall DataFrame with 3588 rows and 3 columns that summarizes the fractional change in the expanding mean of the percentage of medals won for each country in blocks.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Create a DataFrame `reshaped` by reshaping the DataFrame `fractions_change` with `pd.melt()`.\n",
    "- You'll need to use the keyword argument `id_vars='Edition'` to set the identifier variable.\n",
    "- You'll also need to use the keyword argument `value_name='Change'` to set the measured variables.\n",
    "- Print the shape of the DataFrames `reshaped` and `fractions_change`. This has been done for you.\n",
    "- Create a DataFrame `chn` by extracting all the rows from `reshaped` in which the three letter code for each country (`'NOC'`) is `'CHN'`.\n",
    "- Print the last 5 rows of the DataFrame `chn` using the `.tail()` method. This has been done for you, so hit 'Submit Answer' to see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3588, 3) (26, 139)\n",
      "     Edition  NOC     Change\n",
      "567     1992  CHN   4.240630\n",
      "568     1996  CHN   7.860247\n",
      "569     2000  CHN  -3.851278\n",
      "570     2004  CHN   0.128863\n",
      "571     2008  CHN  13.251332\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# Reshape fractions_change: reshaped\n",
    "reshaped = pd.melt(fractions_change, id_vars=['Edition'], value_name = 'Change')\n",
    "\n",
    "# Print reshaped.shape and fractions_change.shape\n",
    "print(reshaped.shape, fractions_change.shape)\n",
    "\n",
    "# Extract rows from reshaped where 'NOC' == 'CHN': chn\n",
    "chn = reshaped[reshaped.loc[:, 'NOC'] == 'CHN']\n",
    "\n",
    "# Print last 5 rows of chn with .tail()\n",
    "print(chn.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging to compute influence\n",
    "\n",
    "This exercise starts off with the DataFrames `reshaped` and `hosts` in the namespace.\n",
    "\n",
    "Your task is to merge the two DataFrames and tidy the result.\n",
    "\n",
    "The end result is a DataFrame summarizing the fractional change in the expanding mean of the percentage of medals won for the *host country* in each Olympic edition.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Merge `reshaped` and `hosts` using an inner join. Remember, `how='inner'` is the default behavior for pd.merge().\n",
    "- Print the first 5 rows of the DataFrame `merged`. This has been done for you. You should see that the rows are jumbled chronologically.\n",
    "- Set the index of `merged` to be `'Edition'` and sort the index.\n",
    "- Print the first 5 rows of the DataFrame `influence`. This has been done for you, so hit 'Submit Answer' to see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Edition</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>1964</td>\n",
       "      <td>JAM</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>1996</td>\n",
       "      <td>IOP</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>2004</td>\n",
       "      <td>KUW</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>2004</td>\n",
       "      <td>SRB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>1912</td>\n",
       "      <td>FIN</td>\n",
       "      <td>54.944477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Edition  NOC     Change\n",
       "1652     1964  JAM   0.000000\n",
       "1452     1996  IOP   0.000000\n",
       "1844     2004  KUW   0.000000\n",
       "2806     2004  SRB        NaN\n",
       "1044     1912  FIN  54.944477"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remember how reshaped look liked\n",
    "reshaped.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Edition</th>\n",
       "      <th>NOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1896</td>\n",
       "      <td>GRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Edition  NOC\n",
       "0     1896  GRE\n",
       "1     1900  FRA"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data for the host countries\n",
    "hosts.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Edition  NOC     Change\n",
      "0     1956  AUS  54.615063\n",
      "1     2000  AUS  12.554986\n",
      "2     1920  BEL  54.757887\n",
      "3     1976  CAN  -2.143977\n",
      "4     2008  CHN  13.251332\n",
      "         NOC      Change\n",
      "Edition                 \n",
      "1896     GRE         NaN\n",
      "1900     FRA  198.002486\n",
      "1904     USA  199.651245\n",
      "1908     GBR  134.489218\n",
      "1912     SWE   71.896226\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# Merge reshaped and hosts: merged\n",
    "merged = pd.merge(reshaped, hosts, how='inner')\n",
    "\n",
    "# Print first 5 rows of merged\n",
    "print(merged.head())\n",
    "\n",
    "# Set Index of merged and sort it: influence\n",
    "influence = merged.set_index('Edition').sort_index()\n",
    "\n",
    "# Print first 5 rows of influence\n",
    "print(influence.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `hosts` dataframe is just comprised of hosts country, it is a smaller dataframe. `reshaped` dataframe is **(3588, 3)** whereas `hosts` dataframe is shaped like **(26, 2)**. Therefore, `merged` dataframe after merging is **(26, 3)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting influence of host country\n",
    "\n",
    "This final exercise starts off with the DataFrames `influence` and `editions` in the namespace. Your job is to plot the influence of being a host country.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Create a Series called `change` by extracting the `'Change'` column from `influence`.\n",
    "- Create a bar plot of `change` using the `.plot()` method with `kind='bar'`. Save the result as `ax` to permit further customization.\n",
    "- Customize the bar plot of `change` to improve readability:\n",
    "- Apply the method `.set_ylabel(\"% Change of Host Country Medal Count\")` to `ax`.\n",
    "- Apply the method `.set_title(\"Is there a Host Country Advantage?\")` to `ax`.\n",
    "- Apply the method `.set_xticklabels(editions['City'])` to `ax`.\n",
    "- Reveal the final plot using `plt.show()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import pyplot\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract influence['Change']: change\n",
    "change = influence['Change']\n",
    "\n",
    "# Make bar plot of change: ax\n",
    "ax = change.plot(kind='bar')\n",
    "\n",
    "# Customize the plot to improve readability\n",
    "ax.set_ylabel(\"% Change of Host Country Medal Count\")\n",
    "ax.set_title(\"Is there a Host Country Advantage?\")\n",
    "ax.set_xticklabels(editions['City'])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
